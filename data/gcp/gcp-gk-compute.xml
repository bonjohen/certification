<?xml version='1.0' encoding='UTF-8'?>
<certification-exam xmlns="http://certification.study/schema/v1" version="1.0">
  <metadata>
    <exam-code>GCP-GK-COMPUTE</exam-code>
    <exam-title>GCP: Compute Services</exam-title>
    <provider>Google Cloud</provider>
    <description>Scenario-Based Study Companion for GCP Compute Services - covers Compute Engine, App Engine, Cloud Functions, Cloud Run, GKE, instance groups, autoscaling, preemptible/spot VMs, and GPUs/TPUs.</description>
    <total-questions>50</total-questions>
    <created-date>2026-01-21</created-date>
    <last-modified>2026-01-21T00:00:00Z</last-modified>
    <categories>
      <category id="cat-virtual-machines">Virtual Machines</category>
      <category id="cat-serverless">Serverless Compute</category>
      <category id="cat-containers">Container Platforms</category>
      <category id="cat-autoscaling">Autoscaling</category>
      <category id="cat-cost-optimization">Cost Optimization</category>
    </categories>
  </metadata>

  <questions>
    <question id="1" category-ref="cat-virtual-machines" difficulty="basic">
      <title>Compute Engine Overview</title>
      <scenario>A company is migrating their on-premises virtual machine workloads to GCP. They need full control over the operating system and installed software.</scenario>
      <question-text>Which GCP service provides virtual machines with full control over the OS?</question-text>
      <choices>
        <choice letter="A">App Engine</choice>
        <choice letter="B">Compute Engine</choice>
        <choice letter="C">Cloud Functions</choice>
        <choice letter="D">Cloud Run</choice>
      </choices>
      <correct-answer>B</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Compute Engine is GCP's IaaS offering for virtual machines.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>Compute Engine provides virtual machines running on Google's infrastructure. You have full control over the OS, can install any software, and manage the VM like a physical server. It's ideal for lift-and-shift migrations.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>Compute Engine offers predefined and custom machine types.</li>
              <li>Supports Windows, Linux, and custom images.</li>
              <li>Provides sole-tenant nodes for compliance requirements requiring physical isolation.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Compute Engine</tag>
        <tag>IaaS</tag>
        <tag>Virtual Machines</tag>
      </tags>
    </question>

    <question id="2" category-ref="cat-virtual-machines" difficulty="basic">
      <title>Machine Type Selection</title>
      <scenario>A data science team needs VMs with high memory-to-CPU ratio for running in-memory analytics workloads.</scenario>
      <question-text>Which Compute Engine machine type family should they choose?</question-text>
      <choices>
        <choice letter="A">Accelerator-optimized (A2)</choice>
        <choice letter="B">Compute-optimized (C series)</choice>
        <choice letter="C">General-purpose (E2/N2)</choice>
        <choice letter="D">Memory-optimized (M series)</choice>
      </choices>
      <correct-answer>D</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Memory-optimized machines have the highest memory-to-vCPU ratios.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>Memory-optimized (M series) machine types provide up to 12 TB of memory, ideal for in-memory databases like SAP HANA, Redis, or in-memory analytics. They offer the highest memory-to-vCPU ratios available.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>M1 and M2 machine types support up to 12 TB RAM.</li>
              <li>M3 machines offer even better price-performance for memory-intensive workloads.</li>
              <li>Compute-optimized (C series) is for CPU-intensive workloads; accelerator-optimized (A2) is for ML training.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Machine Types</tag>
        <tag>Memory-Optimized</tag>
        <tag>Compute Engine</tag>
      </tags>
    </question>

    <question id="3" category-ref="cat-virtual-machines" difficulty="intermediate">
      <title>Custom Machine Types</title>
      <scenario>Your application requires 6 vCPUs and 24 GB of memory, but no predefined machine type matches this configuration exactly.</scenario>
      <question-text>How can you create a VM with this exact configuration?</question-text>
      <choices>
        <choice letter="A">Custom configurations are not supported in Compute Engine</choice>
        <choice letter="B">Use the closest predefined machine type and ignore the extra resources</choice>
        <choice letter="C">Deploy two smaller VMs and load balance between them</choice>
        <choice letter="D">Create a custom machine type with the specific vCPU and memory values</choice>
      </choices>
      <correct-answer>D</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Custom machine types let you specify exact vCPU and memory configurations.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>Compute Engine allows custom machine types where you specify the exact number of vCPUs and amount of memory. This avoids over-provisioning and paying for unused resources. Memory must be between 0.9 GB and 6.5 GB per vCPU.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>Custom machine types are available in N1, N2, N2D, and E2 families.</li>
              <li>Extended memory configurations allow up to 8 GB per vCPU (at additional cost).</li>
              <li>vCPU count must be 1 or an even number; memory must be multiples of 256 MB.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Custom Machine Types</tag>
        <tag>Cost Optimization</tag>
        <tag>Compute Engine</tag>
      </tags>
    </question>

    <question id="4" category-ref="cat-cost-optimization" difficulty="basic">
      <title>Preemptible VMs</title>
      <scenario>A batch processing job can tolerate interruptions and needs to minimize costs. The job can checkpoint and resume if interrupted.</scenario>
      <question-text>Which VM type offers the lowest cost for fault-tolerant batch workloads?</question-text>
      <choices>
        <choice letter="A">Standard on-demand VMs</choice>
        <choice letter="B">Spot VMs (formerly preemptible VMs)</choice>
        <choice letter="C">Sole-tenant nodes</choice>
        <choice letter="D">Committed use VMs</choice>
      </choices>
      <correct-answer>B</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Spot VMs offer up to 91% discount but can be preempted with 30-second notice.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>Spot VMs (the evolution of preemptible VMs) use excess Compute Engine capacity at steep discounts (60-91% off). They can be terminated if Google needs the capacity back, making them ideal for fault-tolerant batch jobs that can checkpoint and restart.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>Spot VMs have no minimum or maximum runtime (unlike legacy preemptible 24-hour limit).</li>
              <li>Use shutdown scripts to save state before termination.</li>
              <li>Combine with managed instance groups for automatic recreation after preemption.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Spot VMs</tag>
        <tag>Preemptible</tag>
        <tag>Cost Optimization</tag>
      </tags>
    </question>

    <question id="5" category-ref="cat-cost-optimization" difficulty="intermediate">
      <title>Committed Use Discounts</title>
      <scenario>Your company runs steady-state production workloads that require consistent compute capacity for the next three years.</scenario>
      <question-text>Which pricing model provides the best discount for predictable long-term workloads?</question-text>
      <choices>
        <choice letter="A">Committed use discounts (CUDs)</choice>
        <choice letter="B">Sustained use discounts</choice>
        <choice letter="C">Spot VM pricing</choice>
        <choice letter="D">On-demand pricing</choice>
      </choices>
      <correct-answer>A</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>CUDs provide up to 70% discount for 1 or 3-year commitments.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>Committed use discounts (CUDs) offer up to 57% off for 1-year and 70% off for 3-year commitments. You commit to a minimum usage level, and the discount applies automatically. Ideal for predictable production workloads.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>CUDs can be resource-based (vCPUs, memory) or spend-based.</li>
              <li>Commitments are regional and apply across projects in that region.</li>
              <li>Sustained use discounts are automatic but max out at 30%; CUDs offer deeper savings.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Committed Use Discounts</tag>
        <tag>Cost Optimization</tag>
        <tag>Pricing</tag>
      </tags>
    </question>

    <question id="6" category-ref="cat-serverless" difficulty="basic">
      <title>App Engine Standard Environment</title>
      <scenario>A startup wants to deploy a Python web application without managing servers. They expect variable traffic and want to pay only when the app is handling requests.</scenario>
      <question-text>Which GCP service automatically scales to zero and charges only for actual usage?</question-text>
      <choices>
        <choice letter="A">App Engine standard environment</choice>
        <choice letter="B">Compute Engine with autoscaling</choice>
        <choice letter="C">App Engine flexible environment</choice>
        <choice letter="D">GKE Autopilot</choice>
      </choices>
      <correct-answer>A</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>App Engine standard can scale to zero instances when idle.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>App Engine standard environment is fully managed PaaS that scales automatically, including to zero instances when there's no traffic. You pay only for the resources used when handling requests. It supports Python, Java, Node.js, PHP, Ruby, and Go.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>Standard environment has faster scaling and startup times than flexible.</li>
              <li>Uses sandboxed runtime; some libraries and features are restricted.</li>
              <li>Flexible environment uses containers and has minimum one instance (doesn't scale to zero).</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>App Engine</tag>
        <tag>Serverless</tag>
        <tag>PaaS</tag>
      </tags>
    </question>

    <question id="7" category-ref="cat-serverless" difficulty="intermediate">
      <title>App Engine Flexible vs Standard</title>
      <scenario>A team needs to deploy a web application that uses custom C++ libraries and requires WebSocket support.</scenario>
      <question-text>Which App Engine environment supports custom runtimes and native WebSocket connections?</question-text>
      <choices>
        <choice letter="A">App Engine standard environment</choice>
        <choice letter="B">App Engine flexible environment</choice>
        <choice letter="C">Neither - use Compute Engine instead</choice>
        <choice letter="D">Both environments support custom runtimes equally</choice>
      </choices>
      <correct-answer>B</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Flexible environment runs containers and supports custom runtimes.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>App Engine flexible environment runs your application in Docker containers on Compute Engine VMs. It supports custom runtimes, any language, native WebSockets, and SSH access. Standard environment is more restricted but scales faster.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>Flexible environment instances take minutes to start; standard takes seconds.</li>
              <li>Flexible supports any runtime via Dockerfiles; standard supports specific languages.</li>
              <li>Standard uses instance hours pricing; flexible uses underlying Compute Engine pricing.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>App Engine</tag>
        <tag>Flexible Environment</tag>
        <tag>Custom Runtimes</tag>
      </tags>
    </question>

    <question id="8" category-ref="cat-serverless" difficulty="basic">
      <title>Cloud Functions Use Case</title>
      <scenario>A developer needs to automatically resize images uploaded to Cloud Storage without maintaining any servers.</scenario>
      <question-text>Which GCP service is best suited for running event-triggered code without managing infrastructure?</question-text>
      <choices>
        <choice letter="A">Cloud Composer</choice>
        <choice letter="B">Compute Engine</choice>
        <choice letter="C">GKE</choice>
        <choice letter="D">Cloud Functions</choice>
      </choices>
      <correct-answer>D</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Cloud Functions executes code in response to events from GCP services.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>Cloud Functions is a serverless, event-driven compute service. Functions can be triggered by Cloud Storage events, Pub/Sub messages, HTTP requests, or Firebase events. You only pay for execution time, with no servers to manage.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>Cloud Functions 2nd gen is built on Cloud Run for longer timeouts (up to 60 minutes).</li>
              <li>Supports Node.js, Python, Go, Java, .NET, Ruby, and PHP.</li>
              <li>Automatic scaling based on incoming requests; scales to zero when idle.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Cloud Functions</tag>
        <tag>Serverless</tag>
        <tag>Event-Driven</tag>
      </tags>
    </question>

    <question id="9" category-ref="cat-serverless" difficulty="intermediate">
      <title>Cloud Functions Triggers</title>
      <scenario>You need to process messages from a Pub/Sub topic and also expose an HTTP endpoint for external API calls.</scenario>
      <question-text>How can Cloud Functions be triggered?</question-text>
      <choices>
        <choice letter="A">Both HTTP requests and event triggers (Pub/Sub, Cloud Storage, etc.)</choice>
        <choice letter="B">HTTP requests only</choice>
        <choice letter="C">Event triggers only</choice>
        <choice letter="D">Only through Cloud Scheduler</choice>
      </choices>
      <correct-answer>A</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Cloud Functions supports both HTTP and event-based triggers.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>Cloud Functions can be triggered by HTTP requests (direct invocation with a URL) or by events from GCP services like Cloud Storage, Pub/Sub, Firestore, and Firebase. This makes them versatile for APIs and event processing.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>HTTP functions get a unique URL endpoint; event functions subscribe to event sources.</li>
              <li>Eventarc (2nd gen) supports 90+ event sources including Audit Logs.</li>
              <li>Use Cloud Scheduler with HTTP functions for cron-like scheduled execution.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Cloud Functions</tag>
        <tag>Triggers</tag>
        <tag>Pub/Sub</tag>
      </tags>
    </question>

    <question id="10" category-ref="cat-serverless" difficulty="intermediate">
      <title>Cloud Run Overview</title>
      <scenario>A team wants to deploy containerized applications without managing Kubernetes clusters, with automatic scaling and pay-per-use pricing.</scenario>
      <question-text>Which GCP service runs containers in a fully managed serverless environment?</question-text>
      <choices>
        <choice letter="A">GKE Standard</choice>
        <choice letter="B">Cloud Run</choice>
        <choice letter="C">Compute Engine with containers</choice>
        <choice letter="D">App Engine standard</choice>
      </choices>
      <correct-answer>B</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Cloud Run is a fully managed serverless platform for containers.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>Cloud Run is a fully managed compute platform that runs stateless containers. It automatically scales based on traffic, including to zero, and you pay only for resources used during request handling. No Kubernetes knowledge required.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>Cloud Run is built on Knative, providing Kubernetes portability.</li>
              <li>Supports any language or library that can be containerized.</li>
              <li>Cloud Run for Anthos runs on your GKE cluster for hybrid scenarios.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Cloud Run</tag>
        <tag>Serverless</tag>
        <tag>Containers</tag>
      </tags>
    </question>

    <question id="11" category-ref="cat-serverless" difficulty="intermediate">
      <title>Cloud Run vs Cloud Functions</title>
      <scenario>You need to run a containerized application that handles HTTP requests and requires custom system libraries. The application has complex dependencies.</scenario>
      <question-text>Why might Cloud Run be preferred over Cloud Functions for this scenario?</question-text>
      <choices>
        <choice letter="A">Cloud Functions cannot handle HTTP requests</choice>
        <choice letter="B">Cloud Functions has better scaling capabilities</choice>
        <choice letter="C">Cloud Run is always cheaper than Cloud Functions</choice>
        <choice letter="D">Cloud Run supports any container image with any dependencies</choice>
      </choices>
      <correct-answer>D</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Cloud Run runs any container; Cloud Functions has runtime constraints.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>Cloud Run accepts any container image, giving you full control over the runtime, dependencies, and system libraries. Cloud Functions has specific supported runtimes and dependency constraints. For complex applications with custom requirements, Cloud Run offers more flexibility.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>Cloud Functions 2nd gen is actually built on Cloud Run under the hood.</li>
              <li>Cloud Run supports longer request timeouts (up to 60 minutes) vs Functions (9 minutes for 1st gen).</li>
              <li>Cloud Run allows multiple concurrent requests per instance; Functions 1st gen processes one at a time.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Cloud Run</tag>
        <tag>Cloud Functions</tag>
        <tag>Containers</tag>
      </tags>
    </question>

    <question id="12" category-ref="cat-containers" difficulty="basic">
      <title>GKE Overview</title>
      <scenario>A company wants to run containerized microservices with full Kubernetes features including custom resource definitions and service mesh.</scenario>
      <question-text>Which GCP service provides managed Kubernetes clusters?</question-text>
      <choices>
        <choice letter="A">Google Kubernetes Engine (GKE)</choice>
        <choice letter="B">Cloud Run</choice>
        <choice letter="C">Compute Engine</choice>
        <choice letter="D">App Engine flexible</choice>
      </choices>
      <correct-answer>A</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>GKE is Google's managed Kubernetes service.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>Google Kubernetes Engine (GKE) provides managed Kubernetes clusters. Google manages the control plane, handles upgrades, and integrates with GCP services. You can use all Kubernetes features including CRDs, operators, and service meshes like Istio.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>GKE Standard: You manage node pools and configurations.</li>
              <li>GKE Autopilot: Google manages nodes; pay per pod resource requests.</li>
              <li>GKE integrates with Cloud Build, Artifact Registry, and Binary Authorization.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>GKE</tag>
        <tag>Kubernetes</tag>
        <tag>Containers</tag>
      </tags>
    </question>

    <question id="13" category-ref="cat-containers" difficulty="intermediate">
      <title>GKE Autopilot vs Standard</title>
      <scenario>A team wants to run Kubernetes workloads with minimal operational overhead. They prefer paying only for the pods they run, not for node capacity.</scenario>
      <question-text>Which GKE mode should they use?</question-text>
      <choices>
        <choice letter="A">GKE Autopilot</choice>
        <choice letter="B">GKE Standard with manual node management</choice>
        <choice letter="C">GKE Standard with cluster autoscaler</choice>
        <choice letter="D">Cloud Run instead of GKE</choice>
      </choices>
      <correct-answer>A</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>GKE Autopilot manages nodes and charges per pod resource usage.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>GKE Autopilot is a mode where Google manages the entire cluster infrastructure including nodes. You only pay for the CPU, memory, and storage requested by your pods. It enforces security best practices and reduces operational overhead.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>Autopilot pre-configures nodes with hardened security settings.</li>
              <li>You cannot SSH to nodes or run privileged containers in Autopilot.</li>
              <li>Standard mode offers more control but requires node pool management.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>GKE Autopilot</tag>
        <tag>Kubernetes</tag>
        <tag>Managed Services</tag>
      </tags>
    </question>

    <question id="14" category-ref="cat-containers" difficulty="intermediate">
      <title>GKE Node Pools</title>
      <scenario>You need to run ML training jobs requiring GPUs alongside web services that need standard CPUs in the same GKE cluster.</scenario>
      <question-text>How should you configure the GKE cluster to support both workload types?</question-text>
      <choices>
        <choice letter="A">GKE does not support mixed machine types</choice>
        <choice letter="B">Use a single node pool with the largest machine type</choice>
        <choice letter="C">Create separate clusters for each workload type</choice>
        <choice letter="D">Create separate node pools with different machine types and use node selectors</choice>
      </choices>
      <correct-answer>D</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Node pools allow different machine types in the same cluster.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>GKE node pools are groups of nodes with the same configuration. You can create multiple node pools with different machine types (including GPU-enabled), and use Kubernetes node selectors or node affinity to schedule pods appropriately.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>Use taints and tolerations to prevent non-GPU workloads from scheduling on GPU nodes.</li>
              <li>Each node pool can have its own autoscaling configuration.</li>
              <li>Node auto-provisioning can automatically create node pools based on pod requirements.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>GKE</tag>
        <tag>Node Pools</tag>
        <tag>GPU</tag>
      </tags>
    </question>

    <question id="15" category-ref="cat-autoscaling" difficulty="basic">
      <title>Managed Instance Groups</title>
      <scenario>You need to deploy a stateless web application across multiple VMs with automatic healing and load distribution.</scenario>
      <question-text>Which Compute Engine feature manages groups of identical VM instances?</question-text>
      <choices>
        <choice letter="A">Unmanaged Instance Groups</choice>
        <choice letter="B">Managed Instance Groups (MIGs)</choice>
        <choice letter="C">Sole-tenant Nodes</choice>
        <choice letter="D">VM Templates</choice>
      </choices>
      <correct-answer>B</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>MIGs manage identical VMs based on an instance template.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>Managed Instance Groups (MIGs) create and manage groups of identical VM instances from an instance template. MIGs provide autoscaling, autohealing (replacing unhealthy instances), and automatic updates with rolling deployments.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>MIGs can be zonal (single zone) or regional (multiple zones for HA).</li>
              <li>Autohealing uses health checks to detect and replace failed instances.</li>
              <li>Unmanaged instance groups are for heterogeneous VMs you manage manually.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Managed Instance Groups</tag>
        <tag>Autoscaling</tag>
        <tag>High Availability</tag>
      </tags>
    </question>

    <question id="16" category-ref="cat-autoscaling" difficulty="intermediate">
      <title>MIG Autoscaling Policies</title>
      <scenario>Your web application needs to scale based on the number of requests per second, maintaining an average of 100 RPS per instance.</scenario>
      <question-text>Which autoscaling metric should you configure for the managed instance group?</question-text>
      <choices>
        <choice letter="A">HTTP load balancing serving capacity with target utilization</choice>
        <choice letter="B">CPU utilization only</choice>
        <choice letter="C">Memory utilization only</choice>
        <choice letter="D">Fixed number of instances</choice>
      </choices>
      <correct-answer>A</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Load balancing metrics can scale based on requests per instance.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>MIG autoscaling supports multiple metrics including CPU, memory, load balancing capacity, Pub/Sub queue depth, and custom Cloud Monitoring metrics. For HTTP-based scaling, use load balancing serving capacity to maintain a target RPS per instance.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>Multiple scaling metrics can be combined; the autoscaler uses the metric requiring the most instances.</li>
              <li>Scale-in controls prevent rapid scale-down during traffic fluctuations.</li>
              <li>Predictive autoscaling uses ML to anticipate traffic patterns and pre-warm instances.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Autoscaling</tag>
        <tag>MIG</tag>
        <tag>Load Balancing</tag>
      </tags>
    </question>

    <question id="17" category-ref="cat-autoscaling" difficulty="intermediate">
      <title>Regional MIGs</title>
      <scenario>You need to deploy a stateless application that remains available even if an entire zone fails.</scenario>
      <question-text>Which configuration provides zone-level fault tolerance for managed instance groups?</question-text>
      <choices>
        <choice letter="A">Zonal managed instance group with larger instances</choice>
        <choice letter="B">Regional managed instance group spread across multiple zones</choice>
        <choice letter="C">Multiple separate zonal MIGs with manual failover</choice>
        <choice letter="D">Single VM with high availability enabled</choice>
      </choices>
      <correct-answer>B</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Regional MIGs distribute instances across zones automatically.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>Regional managed instance groups automatically distribute instances across multiple zones in a region. If a zone fails, instances in other zones continue serving traffic. The autoscaler maintains the target size by creating instances in healthy zones.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>Regional MIGs can use up to 3 zones in a region.</li>
              <li>Distribution is even by default; use target distribution shape for custom distribution.</li>
              <li>Combine with regional load balancers for automatic failover.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Regional MIG</tag>
        <tag>High Availability</tag>
        <tag>Fault Tolerance</tag>
      </tags>
    </question>

    <question id="18" category-ref="cat-autoscaling" difficulty="advanced">
      <title>GKE Cluster Autoscaler</title>
      <scenario>Your GKE cluster has pods pending due to insufficient resources, but the current nodes are fully utilized.</scenario>
      <question-text>What does the GKE cluster autoscaler do in this situation?</question-text>
      <choices>
        <choice letter="A">Terminates lower-priority pods</choice>
        <choice letter="B">Increases CPU limits on existing nodes</choice>
        <choice letter="C">Migrates pods to other clusters</choice>
        <choice letter="D">Adds new nodes to accommodate pending pods</choice>
      </choices>
      <correct-answer>D</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Cluster autoscaler adds nodes when pods cannot be scheduled.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>GKE cluster autoscaler monitors for pods that cannot be scheduled due to insufficient resources and automatically adds nodes to the node pool. It also removes underutilized nodes when pods can be rescheduled elsewhere, reducing costs.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>Configure min/max nodes per node pool to control scaling bounds.</li>
              <li>Use pod disruption budgets to control how aggressively nodes are removed.</li>
              <li>Node auto-provisioning creates new node pools automatically based on pod requirements.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>GKE</tag>
        <tag>Cluster Autoscaler</tag>
        <tag>Kubernetes</tag>
      </tags>
    </question>

    <question id="19" category-ref="cat-virtual-machines" difficulty="intermediate">
      <title>Instance Templates</title>
      <scenario>You need to ensure all VMs in your managed instance group have identical configurations including machine type, disk, and startup script.</scenario>
      <question-text>What should you create to define the VM configuration for a managed instance group?</question-text>
      <choices>
        <choice letter="A">Machine image</choice>
        <choice letter="B">Instance template</choice>
        <choice letter="C">Snapshot</choice>
        <choice letter="D">Custom image</choice>
      </choices>
      <correct-answer>B</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Instance templates define the configuration for VMs in a MIG.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>Instance templates are resources that define VM properties including machine type, boot disk image, network, and metadata (like startup scripts). MIGs use instance templates to create identical instances. Templates are immutable; create new versions for changes.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>Use regional instance templates for regional MIGs to avoid cross-region dependencies.</li>
              <li>Machine images capture everything including multiple disks and state.</li>
              <li>Update MIGs by pointing to a new template and using rolling update policies.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Instance Templates</tag>
        <tag>MIG</tag>
        <tag>Configuration</tag>
      </tags>
    </question>

    <question id="20" category-ref="cat-virtual-machines" difficulty="intermediate">
      <title>GPU Workloads</title>
      <scenario>A machine learning team needs to train deep learning models and requires NVIDIA GPUs attached to their VMs.</scenario>
      <question-text>How do you add GPUs to Compute Engine VMs?</question-text>
      <choices>
        <choice letter="A">Attach GPUs to supported machine types and install GPU drivers</choice>
        <choice letter="B">GPUs are automatically available on all machine types</choice>
        <choice letter="C">Use special GPU-only VMs that cannot have CPUs</choice>
        <choice letter="D">GPUs can only be used with Kubernetes, not raw VMs</choice>
      </choices>
      <correct-answer>A</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>GPUs are attached to VMs; you must install drivers separately.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>GPUs can be attached to specific machine types (N1, A2, G2). You select the GPU type and count when creating the VM. GPU drivers must be installed - use deep learning VM images or install NVIDIA drivers manually. GPUs are available in specific zones.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>A2 and G2 machine types have GPUs built-in (A100 and L4 respectively).</li>
              <li>N1 machines support attaching NVIDIA T4, P4, P100, V100, and K80 GPUs.</li>
              <li>Use Deep Learning VM images for pre-installed GPU drivers and ML frameworks.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>GPU</tag>
        <tag>Machine Learning</tag>
        <tag>Compute Engine</tag>
      </tags>
    </question>

    <question id="21" category-ref="cat-virtual-machines" difficulty="advanced">
      <title>TPU for ML Training</title>
      <scenario>Your team is training large transformer models and needs to accelerate training beyond what GPUs can provide cost-effectively.</scenario>
      <question-text>Which Google Cloud hardware accelerator is specifically designed for machine learning workloads at scale?</question-text>
      <choices>
        <choice letter="A">High-memory VMs</choice>
        <choice letter="B">Field-Programmable Gate Arrays (FPGAs)</choice>
        <choice letter="C">Standard CPUs with AVX-512</choice>
        <choice letter="D">Tensor Processing Units (TPUs)</choice>
      </choices>
      <correct-answer>D</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>TPUs are Google's custom chips optimized for TensorFlow and ML.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>Tensor Processing Units (TPUs) are Google's custom-developed ASICs designed for accelerating machine learning workloads. They excel at large-scale training and inference for models built with TensorFlow, JAX, and PyTorch. TPU pods can scale to thousands of chips.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>TPU v4 provides 275 TFLOPS; TPU v5e is optimized for inference efficiency.</li>
              <li>Cloud TPU VMs give direct access to TPU hosts for better performance.</li>
              <li>TPU pods interconnect many TPUs with high-bandwidth links for distributed training.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>TPU</tag>
        <tag>Machine Learning</tag>
        <tag>Hardware Accelerators</tag>
      </tags>
    </question>

    <question id="22" category-ref="cat-cost-optimization" difficulty="intermediate">
      <title>Sustained Use Discounts</title>
      <scenario>Your VMs run continuously throughout the month. You want automatic discounts without making commitments.</scenario>
      <question-text>Which discount is automatically applied to VMs running for a significant portion of the month?</question-text>
      <choices>
        <choice letter="A">Spot VM pricing</choice>
        <choice letter="B">Committed use discounts</choice>
        <choice letter="C">Sustained use discounts</choice>
        <choice letter="D">Free tier credits</choice>
      </choices>
      <correct-answer>C</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Sustained use discounts apply automatically with no commitment required.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>Sustained use discounts (SUDs) are automatic discounts applied to VMs and GKE nodes that run for more than 25% of a month. The discount increases with usage, up to 30% for instances running the entire month. No action required - applied automatically.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>SUDs apply to vCPUs and memory separately, aggregated across instances of the same type.</li>
              <li>E2 and A2 machine types do not receive sustained use discounts.</li>
              <li>SUDs are applied per region and aggregated across projects.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Sustained Use Discounts</tag>
        <tag>Cost Optimization</tag>
        <tag>Pricing</tag>
      </tags>
    </question>

    <question id="23" category-ref="cat-cost-optimization" difficulty="intermediate">
      <title>Right-sizing Recommendations</title>
      <scenario>Your VMs have been running for several weeks, and you suspect many are over-provisioned based on actual usage patterns.</scenario>
      <question-text>Which GCP tool provides recommendations for optimizing VM sizes based on actual usage?</question-text>
      <choices>
        <choice letter="A">Cloud Profiler</choice>
        <choice letter="B">Recommender (VM right-sizing recommendations)</choice>
        <choice letter="C">Cloud Trace</choice>
        <choice letter="D">Cloud Debugger</choice>
      </choices>
      <correct-answer>B</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Recommender analyzes VM usage and suggests optimal machine types.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>GCP Recommender analyzes VM utilization metrics over time and provides right-sizing recommendations to reduce costs. It can suggest smaller machine types for underutilized VMs or identify idle resources that can be deleted.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>Recommendations appear in Cloud Console, gcloud CLI, and the Recommender API.</li>
              <li>Recommender also provides idle resource recommendations for disks, IPs, and more.</li>
              <li>Use custom machine types if recommendations suggest non-standard configurations.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Recommender</tag>
        <tag>Right-sizing</tag>
        <tag>Cost Optimization</tag>
      </tags>
    </question>

    <question id="24" category-ref="cat-serverless" difficulty="intermediate">
      <title>Cloud Run Concurrency</title>
      <scenario>Your Cloud Run service handles requests that are CPU-intensive. You want to ensure each container instance handles only one request at a time.</scenario>
      <question-text>Which Cloud Run setting controls how many concurrent requests a single container instance handles?</question-text>
      <choices>
        <choice letter="A">Maximum instances setting</choice>
        <choice letter="B">Minimum instances setting</choice>
        <choice letter="C">Container instance concurrency setting</choice>
        <choice letter="D">CPU allocation setting</choice>
      </choices>
      <correct-answer>C</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Concurrency setting controls requests per container instance.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>Cloud Run's concurrency setting (1-1000) determines how many requests a single container instance handles simultaneously. For CPU-intensive work, set concurrency to 1. For I/O-bound work, higher concurrency improves efficiency and reduces costs.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>Default concurrency is 80; adjust based on your application's characteristics.</li>
              <li>Higher concurrency means fewer instances needed, reducing cold starts and costs.</li>
              <li>Ensure your application is thread-safe for concurrency greater than 1.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Cloud Run</tag>
        <tag>Concurrency</tag>
        <tag>Performance</tag>
      </tags>
    </question>

    <question id="25" category-ref="cat-serverless" difficulty="intermediate">
      <title>Cloud Run Minimum Instances</title>
      <scenario>Your Cloud Run service experiences latency spikes when scaling from zero after periods of no traffic.</scenario>
      <question-text>How can you reduce cold start latency for your Cloud Run service?</question-text>
      <choices>
        <choice letter="A">Reduce container image size only</choice>
        <choice letter="B">Increase maximum instances</choice>
        <choice letter="C">Set minimum instances to keep containers warm</choice>
        <choice letter="D">Cold starts cannot be mitigated in Cloud Run</choice>
      </choices>
      <correct-answer>C</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Minimum instances keeps containers running even without traffic.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>Setting minimum instances greater than 0 keeps container instances warm and ready to handle requests, eliminating cold start latency. You pay for the idle instances, so balance cost against latency requirements. Smaller images also help reduce cold start time.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>Idle minimum instances are billed at a reduced rate when not processing requests.</li>
              <li>Use startup CPU boost to temporarily allocate more CPU during container startup.</li>
              <li>Optimize container images: use distroless bases, lazy load dependencies, minimize initialization.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Cloud Run</tag>
        <tag>Cold Start</tag>
        <tag>Performance</tag>
      </tags>
    </question>

    <question id="26" category-ref="cat-virtual-machines" difficulty="basic">
      <title>Persistent Disks</title>
      <scenario>A VM needs storage that persists independently of the VM lifecycle and can be resized without downtime.</scenario>
      <question-text>Which storage option provides durable block storage for Compute Engine VMs?</question-text>
      <choices>
        <choice letter="A">Persistent Disk</choice>
        <choice letter="B">Local SSD</choice>
        <choice letter="C">Cloud Storage bucket</choice>
        <choice letter="D">RAM disk</choice>
      </choices>
      <correct-answer>A</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Persistent Disks are network-attached block storage that survives VM deletion.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>Persistent Disks are durable network-attached block storage. They persist independently of VMs, support snapshots, can be resized without downtime, and can be attached to multiple VMs (read-only) or moved between VMs.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>Types: pd-standard (HDD), pd-balanced, pd-ssd, pd-extreme (highest IOPS).</li>
              <li>Regional persistent disks replicate across two zones for high availability.</li>
              <li>Local SSDs offer higher IOPS but data is lost when VM stops.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Persistent Disk</tag>
        <tag>Storage</tag>
        <tag>Compute Engine</tag>
      </tags>
    </question>

    <question id="27" category-ref="cat-virtual-machines" difficulty="intermediate">
      <title>Local SSDs vs Persistent Disks</title>
      <scenario>A database workload requires extremely low latency storage and high IOPS. Data is replicated at the application level, so disk-level durability is not required.</scenario>
      <question-text>Which storage type provides the lowest latency for Compute Engine VMs?</question-text>
      <choices>
        <choice letter="A">SSD Persistent Disk</choice>
        <choice letter="B">Standard Persistent Disk</choice>
        <choice letter="C">Local SSD</choice>
        <choice letter="D">Extreme Persistent Disk</choice>
      </choices>
      <correct-answer>C</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Local SSDs are physically attached to the host machine for lowest latency.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>Local SSDs are physically attached to the server hosting your VM, providing extremely high IOPS and low latency. However, data on local SSDs is ephemeral - it's lost when the VM stops, is preempted, or the host fails. Use for caches or replicated data.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>Local SSDs provide up to 9 TB per VM with 2.4M read IOPS.</li>
              <li>Local SSDs are included with Z3 machine types optimized for storage.</li>
              <li>Data encryption is automatic; local SSDs cannot be detached or snapshotted.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Local SSD</tag>
        <tag>Storage</tag>
        <tag>Performance</tag>
      </tags>
    </question>

    <question id="28" category-ref="cat-containers" difficulty="intermediate">
      <title>GKE Workload Identity</title>
      <scenario>Your GKE pods need to access Cloud Storage buckets securely without embedding service account keys in the application.</scenario>
      <question-text>What is the recommended way to authenticate GKE workloads to Google Cloud services?</question-text>
      <choices>
        <choice letter="A">Service account key files mounted as secrets</choice>
        <choice letter="B">Workload Identity</choice>
        <choice letter="C">Node service account shared by all pods</choice>
        <choice letter="D">Application Default Credentials with user credentials</choice>
      </choices>
      <correct-answer>B</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Workload Identity links Kubernetes service accounts to GCP service accounts.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>Workload Identity is the recommended way for GKE pods to authenticate to Google Cloud APIs. It binds Kubernetes service accounts to GCP IAM service accounts, eliminating the need for service account keys. Pods automatically receive short-lived tokens.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>Workload Identity Federation extends this to non-GCP Kubernetes clusters.</li>
              <li>Enabled by default on Autopilot; optional but recommended on Standard clusters.</li>
              <li>Provides better security than node service account (which all pods would share).</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Workload Identity</tag>
        <tag>GKE</tag>
        <tag>Security</tag>
      </tags>
    </question>

    <question id="29" category-ref="cat-containers" difficulty="advanced">
      <title>GKE Network Policies</title>
      <scenario>You need to restrict network traffic between pods in your GKE cluster so that only the frontend pods can communicate with the backend pods.</scenario>
      <question-text>What should you implement to control pod-to-pod network traffic?</question-text>
      <choices>
        <choice letter="A">VPC firewall rules</choice>
        <choice letter="B">Kubernetes Network Policies</choice>
        <choice letter="C">Cloud Armor policies</choice>
        <choice letter="D">IAM permissions</choice>
      </choices>
      <correct-answer>B</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Network Policies control traffic between pods using labels.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>Kubernetes Network Policies specify how pods are allowed to communicate. They use label selectors to identify pods and define ingress/egress rules. In GKE, network policies require enabling the network policy add-on (Calico or Dataplane V2).</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>GKE Dataplane V2 provides native support for network policies with eBPF.</li>
              <li>Without network policies, all pods can communicate with each other by default.</li>
              <li>VPC firewall rules apply at the node level, not pod level.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Network Policy</tag>
        <tag>GKE</tag>
        <tag>Security</tag>
      </tags>
    </question>

    <question id="30" category-ref="cat-autoscaling" difficulty="intermediate">
      <title>Horizontal Pod Autoscaler</title>
      <scenario>Your GKE deployment needs to automatically scale the number of pods based on CPU utilization, maintaining 70% average utilization.</scenario>
      <question-text>Which Kubernetes resource automatically scales pod replicas based on metrics?</question-text>
      <choices>
        <choice letter="A">Cluster Autoscaler</choice>
        <choice letter="B">Vertical Pod Autoscaler (VPA)</choice>
        <choice letter="C">Horizontal Pod Autoscaler (HPA)</choice>
        <choice letter="D">Node Auto-provisioner</choice>
      </choices>
      <correct-answer>C</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>HPA scales the number of pod replicas based on observed metrics.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>Horizontal Pod Autoscaler (HPA) automatically scales the number of pods in a deployment based on observed CPU, memory, or custom metrics. You define target utilization, and HPA adjusts replicas to maintain that target.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>HPA can scale based on multiple metrics simultaneously.</li>
              <li>Custom metrics from Cloud Monitoring can drive scaling (e.g., queue depth).</li>
              <li>VPA adjusts pod resource requests/limits; use one or the other, not both on same metric.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>HPA</tag>
        <tag>Autoscaling</tag>
        <tag>Kubernetes</tag>
      </tags>
    </question>

    <question id="31" category-ref="cat-autoscaling" difficulty="advanced">
      <title>Vertical Pod Autoscaler</title>
      <scenario>Your pods were initially configured with resource requests that don't match actual usage. You want to automatically adjust CPU and memory requests based on actual consumption.</scenario>
      <question-text>Which GKE feature automatically adjusts pod resource requests based on usage?</question-text>
      <choices>
        <choice letter="A">Vertical Pod Autoscaler (VPA)</choice>
        <choice letter="B">Horizontal Pod Autoscaler (HPA)</choice>
        <choice letter="C">Pod Disruption Budget</choice>
        <choice letter="D">Limit Ranges</choice>
      </choices>
      <correct-answer>A</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>VPA recommends and can automatically set resource requests for pods.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>Vertical Pod Autoscaler (VPA) analyzes pod resource usage and recommends or automatically updates CPU and memory requests. It can operate in recommendation-only mode or auto mode that restarts pods with updated requests.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>VPA modes: Off (recommendations only), Initial (set on pod creation), Auto (update running pods).</li>
              <li>Don't use VPA and HPA on the same metric (e.g., both on CPU).</li>
              <li>VPA requires pod restarts to apply new resource values.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>VPA</tag>
        <tag>Resource Management</tag>
        <tag>Kubernetes</tag>
      </tags>
    </question>

    <question id="32" category-ref="cat-serverless" difficulty="basic">
      <title>Choosing Between Compute Options</title>
      <scenario>A developer wants to run a simple Python script that processes uploaded files. They want minimal infrastructure management and fast deployment.</scenario>
      <question-text>Which service requires the least operational overhead for running event-driven code?</question-text>
      <choices>
        <choice letter="A">GKE Standard</choice>
        <choice letter="B">Compute Engine</choice>
        <choice letter="C">Cloud Functions</choice>
        <choice letter="D">App Engine flexible</choice>
      </choices>
      <correct-answer>C</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Cloud Functions is the most serverless option - just deploy code.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>Cloud Functions has the lowest operational overhead: deploy code directly, no servers or containers to manage, automatic scaling, and pay only for execution time. Ideal for simple event-driven tasks like file processing, webhooks, or scheduled jobs.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>Functions 2nd gen supports longer timeouts and traffic splitting for A/B testing.</li>
              <li>For more complex applications or custom runtimes, consider Cloud Run.</li>
              <li>App Engine flexible requires managing app.yaml and has instance-based pricing.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Cloud Functions</tag>
        <tag>Serverless</tag>
        <tag>Decision Making</tag>
      </tags>
    </question>

    <question id="33" category-ref="cat-virtual-machines" difficulty="intermediate">
      <title>Sole-Tenant Nodes</title>
      <scenario>Your company has licensing requirements that mandate physical separation of workloads from other customers' VMs.</scenario>
      <question-text>Which Compute Engine feature provides dedicated physical servers for your VMs only?</question-text>
      <choices>
        <choice letter="A">Preemptible VMs</choice>
        <choice letter="B">Committed use discounts</choice>
        <choice letter="C">Custom machine types</choice>
        <choice letter="D">Sole-tenant nodes</choice>
      </choices>
      <correct-answer>D</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Sole-tenant nodes dedicate physical servers exclusively to your project.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>Sole-tenant nodes are physical Compute Engine servers dedicated exclusively to your workloads. They help meet compliance requirements for physical isolation, bring-your-own-license (BYOL) scenarios, and workloads that cannot share hardware with others.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>Use node affinity labels to place specific VMs on specific sole-tenant nodes.</li>
              <li>Node templates define the configuration; node groups manage the nodes.</li>
              <li>Sole-tenant nodes support Windows BYOL with license tracking.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Sole-Tenant Nodes</tag>
        <tag>Compliance</tag>
        <tag>Licensing</tag>
      </tags>
    </question>

    <question id="34" category-ref="cat-virtual-machines" difficulty="intermediate">
      <title>Live Migration</title>
      <scenario>Google needs to perform maintenance on the physical host running your VM. You need to ensure your application remains available during this maintenance.</scenario>
      <question-text>Which Compute Engine feature moves VMs between hosts without downtime during maintenance?</question-text>
      <choices>
        <choice letter="A">Snapshot restore</choice>
        <choice letter="B">Live migration</choice>
        <choice letter="C">Instance clone</choice>
        <choice letter="D">Manual failover</choice>
      </choices>
      <correct-answer>B</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Live migration transparently moves running VMs to different hosts.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>Live migration allows Compute Engine to move running VMs from one physical host to another without interruption. This enables Google to perform maintenance without downtime for your applications. Most VMs are configured for live migration by default.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>VMs with GPUs or local SSDs cannot be live migrated; they must terminate.</li>
              <li>Configure on-host maintenance behavior: migrate (default) or terminate.</li>
              <li>Applications may experience brief network latency during migration.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Live Migration</tag>
        <tag>Maintenance</tag>
        <tag>High Availability</tag>
      </tags>
    </question>

    <question id="35" category-ref="cat-serverless" difficulty="intermediate">
      <title>Cloud Run Jobs</title>
      <scenario>You need to run a batch data processing task that executes to completion and then exits. The task should not respond to HTTP requests.</scenario>
      <question-text>Which Cloud Run feature is designed for batch workloads that run to completion?</question-text>
      <choices>
        <choice letter="A">Cloud Run jobs</choice>
        <choice letter="B">Cloud Run services</choice>
        <choice letter="C">Cloud Functions HTTP trigger</choice>
        <choice letter="D">Cloud Scheduler only</choice>
      </choices>
      <correct-answer>A</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Cloud Run jobs execute containers that run to completion without serving requests.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>Cloud Run jobs run containers that perform work and exit, unlike services that listen for requests. Jobs are ideal for batch processing, data migrations, or scheduled tasks. They can run multiple parallel tasks and retry on failure.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>Jobs can be executed manually, via API, or scheduled with Cloud Scheduler.</li>
              <li>Configure task count for parallelism and timeout for long-running tasks.</li>
              <li>Jobs support the same container configurations as services (CPU, memory, secrets).</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Cloud Run Jobs</tag>
        <tag>Batch Processing</tag>
        <tag>Serverless</tag>
      </tags>
    </question>

    <question id="36" category-ref="cat-containers" difficulty="intermediate">
      <title>GKE Private Clusters</title>
      <scenario>Your security team requires that GKE nodes have no public IP addresses and are not accessible from the internet.</scenario>
      <question-text>Which GKE configuration ensures nodes are isolated from public internet access?</question-text>
      <choices>
        <choice letter="A">Cluster with node network policy</choice>
        <choice letter="B">Standard cluster with VPC firewall rules</choice>
        <choice letter="C">Autopilot cluster with default settings</choice>
        <choice letter="D">Private cluster with private nodes</choice>
      </choices>
      <correct-answer>D</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Private clusters give nodes only internal IP addresses.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>GKE private clusters provide nodes with only internal IP addresses, isolating them from the public internet. You can also make the control plane private. Access to the internet requires Cloud NAT for egress traffic.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>Configure authorized networks to restrict which IPs can access the control plane.</li>
              <li>Private Service Connect provides private access to the control plane without public endpoint.</li>
              <li>Use Cloud NAT for nodes to pull container images from public registries.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Private Clusters</tag>
        <tag>GKE</tag>
        <tag>Security</tag>
      </tags>
    </question>

    <question id="37" category-ref="cat-virtual-machines" difficulty="basic">
      <title>VM Startup Scripts</title>
      <scenario>You need to automatically install software and configure settings when a new VM instance starts.</scenario>
      <question-text>How can you automatically run commands when a Compute Engine VM starts?</question-text>
      <choices>
        <choice letter="A">Startup automation is not supported</choice>
        <choice letter="B">Manually SSH and run commands after each start</choice>
        <choice letter="C">Use Cloud Build to modify running VMs</choice>
        <choice letter="D">Use a startup script in VM metadata</choice>
      </choices>
      <correct-answer>D</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Startup scripts in metadata run automatically when VMs boot.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>Compute Engine VMs support startup scripts specified in instance metadata. The script runs automatically each time the VM starts. You can specify inline scripts or URLs to scripts stored in Cloud Storage. Shutdown scripts also available.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>Linux uses startup-script or startup-script-url metadata keys.</li>
              <li>Windows uses windows-startup-script-ps1 or similar keys.</li>
              <li>For complex configurations, consider custom images or configuration management tools.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Startup Scripts</tag>
        <tag>Automation</tag>
        <tag>Compute Engine</tag>
      </tags>
    </question>

    <question id="38" category-ref="cat-cost-optimization" difficulty="advanced">
      <title>Spot VM Limitations</title>
      <scenario>You're considering Spot VMs for a production web server that must maintain 99.9% availability.</scenario>
      <question-text>Why are Spot VMs NOT recommended for this production web server?</question-text>
      <choices>
        <choice letter="A">Spot VMs are more expensive than standard VMs</choice>
        <choice letter="B">Spot VMs have lower network performance</choice>
        <choice letter="C">Spot VMs cannot use load balancers</choice>
        <choice letter="D">Spot VMs can be preempted at any time with 30-second warning</choice>
      </choices>
      <correct-answer>D</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Spot VMs can be terminated anytime, making them unsuitable for critical workloads.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>Spot VMs can be preempted by Google at any time when capacity is needed, with only 30 seconds notice. This makes them unsuitable for production services requiring high availability. They're ideal for fault-tolerant batch processing, not critical web servers.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>No SLA for Spot VMs; availability varies by zone and machine type.</li>
              <li>For production web servers, use standard VMs with committed use discounts instead.</li>
              <li>Spot VMs can be combined with on-demand in MIGs for cost-optimized batch bursting.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Spot VMs</tag>
        <tag>Production Workloads</tag>
        <tag>Availability</tag>
      </tags>
    </question>

    <question id="39" category-ref="cat-containers" difficulty="intermediate">
      <title>Container-Optimized OS</title>
      <scenario>You need to run containers on Compute Engine with a minimal, secure, and auto-updating operating system.</scenario>
      <question-text>Which OS image is optimized for running containers on Compute Engine?</question-text>
      <choices>
        <choice letter="A">CentOS</choice>
        <choice letter="B">Ubuntu Server LTS</choice>
        <choice letter="C">Windows Server with containers</choice>
        <choice letter="D">Container-Optimized OS (COS)</choice>
      </choices>
      <correct-answer>D</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Container-Optimized OS is Google's hardened OS for running containers.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>Container-Optimized OS (COS) is a Google-maintained OS designed for running containers. It's minimal, auto-updates, has a locked-down root filesystem, and includes Docker pre-installed. GKE nodes use COS by default.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>COS images receive automatic security updates.</li>
              <li>Root filesystem is read-only; use cloud-init for configuration.</li>
              <li>Alternatives include COS with containerd (cos-containerd) for GKE.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Container-Optimized OS</tag>
        <tag>Containers</tag>
        <tag>Security</tag>
      </tags>
    </question>

    <question id="40" category-ref="cat-serverless" difficulty="advanced">
      <title>Cloud Run Traffic Splitting</title>
      <scenario>You want to gradually roll out a new version of your Cloud Run service, sending 10% of traffic to the new revision while monitoring for errors.</scenario>
      <question-text>Which Cloud Run feature enables gradual rollouts between revisions?</question-text>
      <choices>
        <choice letter="A">Traffic splitting between revisions</choice>
        <choice letter="B">Multiple Cloud Run services behind a load balancer</choice>
        <choice letter="C">Cloud Run does not support canary deployments</choice>
        <choice letter="D">Manual DNS switching</choice>
      </choices>
      <correct-answer>A</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Cloud Run can split traffic across multiple revisions by percentage.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>Cloud Run supports traffic splitting, allowing you to route percentages of traffic to different revisions. This enables canary deployments, A/B testing, and gradual rollouts. You can also route traffic to specific revisions using revision tags.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>Each revision gets a unique URL via tags for testing before routing traffic.</li>
              <li>Gradual rollouts can be automated with Cloud Deploy for CI/CD pipelines.</li>
              <li>Instant rollback by shifting 100% traffic back to the previous revision.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Cloud Run</tag>
        <tag>Traffic Splitting</tag>
        <tag>Canary Deployment</tag>
      </tags>
    </question>

    <question id="41" category-ref="cat-virtual-machines" difficulty="intermediate">
      <title>Shielded VMs</title>
      <scenario>Your security policy requires protection against rootkits and boot-level malware on all VMs.</scenario>
      <question-text>Which Compute Engine feature provides verified boot integrity and protection against boot-level threats?</question-text>
      <choices>
        <choice letter="A">Custom images</choice>
        <choice letter="B">Confidential VMs</choice>
        <choice letter="C">Sole-tenant nodes</choice>
        <choice letter="D">Shielded VMs</choice>
      </choices>
      <correct-answer>D</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Shielded VMs use secure boot and integrity monitoring.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>Shielded VMs provide verifiable integrity through Secure Boot, vTPM (virtual Trusted Platform Module), and integrity monitoring. They protect against rootkits and boot-level malware by ensuring only trusted software runs during the boot process.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>Secure Boot ensures only signed bootloaders and kernels run.</li>
              <li>vTPM enables measured boot and can store encryption keys.</li>
              <li>Integrity monitoring compares boot measurements against baseline.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Shielded VMs</tag>
        <tag>Security</tag>
        <tag>Boot Integrity</tag>
      </tags>
    </question>

    <question id="42" category-ref="cat-virtual-machines" difficulty="advanced">
      <title>Confidential VMs</title>
      <scenario>You need to process sensitive data and require encryption of data in memory, protecting it even from the hypervisor.</scenario>
      <question-text>Which Compute Engine feature encrypts data while it's being processed in memory?</question-text>
      <choices>
        <choice letter="A">Customer-managed encryption keys</choice>
        <choice letter="B">Shielded VMs</choice>
        <choice letter="C">Confidential VMs</choice>
        <choice letter="D">Private Google Access</choice>
      </choices>
      <correct-answer>C</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Confidential VMs encrypt memory using AMD SEV or Intel TDX.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>Confidential VMs use hardware-based memory encryption (AMD SEV or Intel TDX) to encrypt data while it's being processed in memory. This protects data from the cloud provider, hypervisor, and other VMs, providing confidential computing capabilities.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>Available on N2D (AMD) and C3 (Intel TDX) machine types.</li>
              <li>Confidential GKE nodes run pods with memory encryption.</li>
              <li>Combines with CMEK for encryption at rest and Shielded VMs for boot integrity.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Confidential VMs</tag>
        <tag>Security</tag>
        <tag>Encryption</tag>
      </tags>
    </question>

    <question id="43" category-ref="cat-autoscaling" difficulty="intermediate">
      <title>MIG Rolling Updates</title>
      <scenario>You need to update all VMs in a managed instance group to a new instance template with zero downtime.</scenario>
      <question-text>How should you update VMs in a MIG with minimal disruption?</question-text>
      <choices>
        <choice letter="A">Manually update each VM one at a time</choice>
        <choice letter="B">Delete and recreate the entire MIG</choice>
        <choice letter="C">Use rolling update with maxSurge and maxUnavailable settings</choice>
        <choice letter="D">MIGs do not support updates after creation</choice>
      </choices>
      <correct-answer>C</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Rolling updates gradually replace VMs while maintaining availability.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>MIG rolling updates gradually replace instances with new ones based on the updated instance template. Configure maxSurge (extra instances during update) and maxUnavailable (instances that can be offline) to control the rollout speed and availability.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>Proactive updates replace instances immediately; opportunistic waits for other triggers.</li>
              <li>Canary updates let you test new template on a subset before full rollout.</li>
              <li>Rollback by initiating another update to the previous template.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Rolling Updates</tag>
        <tag>MIG</tag>
        <tag>Deployment</tag>
      </tags>
    </question>

    <question id="44" category-ref="cat-serverless" difficulty="intermediate">
      <title>App Engine Traffic Management</title>
      <scenario>You have deployed a new version of your App Engine application and want to gradually migrate traffic from the old version.</scenario>
      <question-text>How can you control traffic distribution between App Engine versions?</question-text>
      <choices>
        <choice letter="A">App Engine only supports instant cutover</choice>
        <choice letter="B">Use traffic splitting to distribute traffic by percentage</choice>
        <choice letter="C">Deploy to a different project for testing</choice>
        <choice letter="D">Use external load balancer only</choice>
      </choices>
      <correct-answer>B</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>App Engine supports traffic splitting between versions.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>App Engine traffic splitting allows you to distribute traffic between versions by percentage. You can split by IP address (for consistent user experience), cookie, or random. This enables canary deployments and gradual migrations.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>IP-based splitting sends same user to same version; cookie-based is more accurate.</li>
              <li>Each version has a unique URL for direct testing before traffic split.</li>
              <li>Traffic migration can be gradual (automatic increase) or manual.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>App Engine</tag>
        <tag>Traffic Splitting</tag>
        <tag>Deployment</tag>
      </tags>
    </question>

    <question id="45" category-ref="cat-containers" difficulty="advanced">
      <title>GKE Release Channels</title>
      <scenario>Your team wants automatic Kubernetes version upgrades while maintaining stability for production workloads.</scenario>
      <question-text>Which GKE feature provides managed version upgrades with different stability levels?</question-text>
      <choices>
        <choice letter="A">GKE does not support automatic upgrades</choice>
        <choice letter="B">Manual version pinning only</choice>
        <choice letter="C">Automatic upgrade to latest version immediately</choice>
        <choice letter="D">Release channels (Rapid, Regular, Stable)</choice>
      </choices>
      <correct-answer>D</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Release channels provide automatic upgrades with different maturity levels.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>GKE release channels (Rapid, Regular, Stable) provide automatic version management. Rapid gets new features first, Regular is balanced, and Stable is most tested. Channels ensure you're on supported versions with security patches.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>Extended channel provides longer support for stable versions (available for paid support).</li>
              <li>Maintenance windows control when upgrades occur.</li>
              <li>Surge upgrades minimize disruption during node pool upgrades.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Release Channels</tag>
        <tag>GKE</tag>
        <tag>Version Management</tag>
      </tags>
    </question>

    <question id="46" category-ref="cat-cost-optimization" difficulty="intermediate">
      <title>VM Scheduling Options</title>
      <scenario>You have development VMs that are only needed during business hours and should be stopped overnight to save costs.</scenario>
      <question-text>What is the best way to automatically stop VMs on a schedule?</question-text>
      <choices>
        <choice letter="A">Use instance schedules to start/stop VMs automatically</choice>
        <choice letter="B">Manually stop VMs each evening</choice>
        <choice letter="C">Use Spot VMs which stop automatically</choice>
        <choice letter="D">Scheduled VM management is not supported</choice>
      </choices>
      <correct-answer>A</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Instance schedules automate VM start/stop on a defined schedule.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>Compute Engine instance schedules automatically start and stop VMs based on a time schedule. This is ideal for dev/test environments, saving costs by stopping VMs during non-working hours. Schedules use cron-like syntax.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>Create schedule resources and attach them to VMs or instance templates.</li>
              <li>Alternative: Cloud Scheduler triggering Cloud Functions to start/stop VMs.</li>
              <li>Stopped VMs don't incur compute charges but persistent disks are still billed.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Instance Schedules</tag>
        <tag>Cost Optimization</tag>
        <tag>Automation</tag>
      </tags>
    </question>

    <question id="47" category-ref="cat-serverless" difficulty="intermediate">
      <title>Cloud Functions 2nd Generation</title>
      <scenario>Your function needs to run for longer than 9 minutes and requires more memory than 1st generation supports.</scenario>
      <question-text>Which Cloud Functions version supports longer timeouts and more resources?</question-text>
      <choices>
        <choice letter="A">Both generations have identical limits</choice>
        <choice letter="B">Cloud Functions 1st generation with extended timeout</choice>
        <choice letter="C">Cloud Functions does not support long-running tasks</choice>
        <choice letter="D">Cloud Functions 2nd generation</choice>
      </choices>
      <correct-answer>D</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>2nd gen functions built on Cloud Run support up to 60-minute timeouts.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>Cloud Functions 2nd generation is built on Cloud Run and supports longer timeouts (up to 60 minutes vs 9 minutes), more memory (up to 32 GB vs 8 GB), and more vCPUs. It also supports concurrency, traffic splitting, and Eventarc triggers.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>2nd gen supports multiple concurrent requests per instance.</li>
              <li>Eventarc enables triggers from 90+ event sources including Cloud Audit Logs.</li>
              <li>2nd gen provides better cold start performance with min instances.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Cloud Functions</tag>
        <tag>2nd Generation</tag>
        <tag>Serverless</tag>
      </tags>
    </question>

    <question id="48" category-ref="cat-containers" difficulty="intermediate">
      <title>Artifact Registry for Containers</title>
      <scenario>You need a secure, private registry to store container images used by your GKE clusters and Cloud Run services.</scenario>
      <question-text>Which GCP service provides a managed container registry integrated with GKE and Cloud Run?</question-text>
      <choices>
        <choice letter="A">Artifact Registry</choice>
        <choice letter="B">Cloud Storage</choice>
        <choice letter="C">Container Registry (deprecated)</choice>
        <choice letter="D">Cloud Source Repositories</choice>
      </choices>
      <correct-answer>A</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Artifact Registry is the recommended registry for containers and other artifacts.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>Artifact Registry is Google's universal artifact management service for containers, language packages, and OS packages. It integrates with Cloud Build, GKE, and Cloud Run, provides vulnerability scanning, and supports regional and multi-regional repositories.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>Container Registry is deprecated; migrate to Artifact Registry.</li>
              <li>Artifact Registry supports Docker, Maven, npm, Python, and more.</li>
              <li>Binary Authorization integrates with Artifact Registry for image attestation.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Artifact Registry</tag>
        <tag>Container Registry</tag>
        <tag>GKE</tag>
      </tags>
    </question>

    <question id="49" category-ref="cat-virtual-machines" difficulty="intermediate">
      <title>OS Patch Management</title>
      <scenario>You need to ensure all Compute Engine VMs are patched with the latest security updates and maintain compliance reports.</scenario>
      <question-text>Which GCP service manages OS patch deployment and compliance for Compute Engine VMs?</question-text>
      <choices>
        <choice letter="A">OS Patch Management (VM Manager)</choice>
        <choice letter="B">Cloud Build</choice>
        <choice letter="C">Deployment Manager</choice>
        <choice letter="D">Manual SSH patching only</choice>
      </choices>
      <correct-answer>A</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>VM Manager includes OS patch management for compliance.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>VM Manager (OS Patch Management) automates OS patch deployment across Compute Engine VMs. It provides patch compliance reporting, scheduled patch jobs, and supports Windows and Linux. Essential for security compliance and reducing manual maintenance.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>OS Config agent must be installed (pre-installed on most public images).</li>
              <li>Create patch jobs with filters (zones, labels) and rollout settings.</li>
              <li>OS Inventory tracks installed packages and available updates.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Patch Management</tag>
        <tag>VM Manager</tag>
        <tag>Security</tag>
      </tags>
    </question>

    <question id="50" category-ref="cat-serverless" difficulty="advanced">
      <title>Compute Service Selection</title>
      <scenario>A company needs to choose the right GCP compute service for different workloads: a stateless API, a legacy monolithic application requiring specific OS configurations, and a machine learning training pipeline.</scenario>
      <question-text>What is the best mapping of workloads to compute services?</question-text>
      <choices>
        <choice letter="A">GKE for all three workloads</choice>
        <choice letter="B">App Engine for all three workloads</choice>
        <choice letter="C">Cloud Run for stateless API, Compute Engine for legacy app, Vertex AI with GPUs for ML training</choice>
        <choice letter="D">Cloud Functions for all three workloads</choice>
      </choices>
      <correct-answer>C</correct-answer>
      <hints>
        <hint level="1" label="Brief Hint">
          <content>Match compute services to workload requirements: serverless for APIs, VMs for legacy, specialized services for ML.</content>
        </hint>
        <hint level="2" label="Complete Explanation">
          <content>Cloud Run is ideal for stateless, containerized APIs with automatic scaling. Compute Engine provides full VM control needed for legacy applications with specific OS requirements. Vertex AI (with GPU/TPU support) or Compute Engine with GPUs is appropriate for ML training pipelines.</content>
        </hint>
        <hint level="3" label="Deep Knowledge">
          <content>
            <ul>
              <li>Consider: management overhead, scaling needs, runtime requirements, and cost.</li>
              <li>GKE is powerful but adds Kubernetes complexity; use when you need its features.</li>
              <li>Cloud Functions is best for simple event-driven tasks, not full applications.</li>
            </ul>
          </content>
        </hint>
      </hints>
      <tags>
        <tag>Service Selection</tag>
        <tag>Architecture</tag>
        <tag>Decision Making</tag>
      </tags>
    </question>
  </questions>

  <glossary>
    <term id="gl-compute-engine" category="Virtual Machines">
      <name>Compute Engine</name>
      <definition>GCP's Infrastructure as a Service (IaaS) offering that provides virtual machines running on Google's infrastructure with full OS control.</definition>
      <exam-note>Compute Engine is for lift-and-shift migrations and workloads requiring full VM control.</exam-note>
      <related-terms>
        <term-ref>Machine Types</term-ref>
        <term-ref>Persistent Disk</term-ref>
      </related-terms>
    </term>
    <term id="gl-app-engine" category="Serverless">
      <name>App Engine</name>
      <definition>A fully managed Platform as a Service (PaaS) for building and deploying web applications without managing infrastructure.</definition>
      <exam-note>Standard environment scales to zero; flexible environment uses containers with minimum one instance.</exam-note>
      <related-terms>
        <term-ref>Cloud Run</term-ref>
        <term-ref>Cloud Functions</term-ref>
      </related-terms>
    </term>
    <term id="gl-cloud-functions" category="Serverless">
      <name>Cloud Functions</name>
      <definition>A serverless execution environment for building event-driven applications with automatic scaling and pay-per-use pricing.</definition>
      <exam-note>2nd generation supports longer timeouts (60 min) and is built on Cloud Run.</exam-note>
      <related-terms>
        <term-ref>Cloud Run</term-ref>
        <term-ref>Pub/Sub</term-ref>
      </related-terms>
    </term>
    <term id="gl-cloud-run" category="Serverless">
      <name>Cloud Run</name>
      <definition>A fully managed serverless platform for running stateless containers that automatically scales based on incoming requests.</definition>
      <exam-note>Supports any container image; can scale to zero; built on Knative for portability.</exam-note>
      <related-terms>
        <term-ref>Cloud Functions</term-ref>
        <term-ref>GKE</term-ref>
      </related-terms>
    </term>
    <term id="gl-gke" category="Containers">
      <name>Google Kubernetes Engine (GKE)</name>
      <definition>A managed Kubernetes service that provides container orchestration with automatic upgrades, scaling, and integration with GCP services.</definition>
      <exam-note>Autopilot mode manages nodes and charges per pod; Standard mode gives full control over node pools.</exam-note>
      <related-terms>
        <term-ref>Cloud Run</term-ref>
        <term-ref>Node Pools</term-ref>
      </related-terms>
    </term>
    <term id="gl-mig" category="Autoscaling">
      <name>Managed Instance Group (MIG)</name>
      <definition>A group of identical VM instances managed as a single entity with autoscaling, autohealing, and rolling updates.</definition>
      <exam-note>Regional MIGs distribute across zones for high availability; use instance templates for configuration.</exam-note>
      <related-terms>
        <term-ref>Instance Template</term-ref>
        <term-ref>Autoscaling</term-ref>
      </related-terms>
    </term>
    <term id="gl-spot-vm" category="Cost Optimization">
      <name>Spot VM</name>
      <definition>Virtual machines using excess Compute Engine capacity at 60-91% discount, which can be preempted with 30-second notice.</definition>
      <exam-note>Ideal for fault-tolerant batch workloads; not suitable for production services requiring high availability.</exam-note>
      <related-terms>
        <term-ref>Preemptible VM</term-ref>
        <term-ref>Committed Use Discount</term-ref>
      </related-terms>
    </term>
    <term id="gl-cud" category="Cost Optimization">
      <name>Committed Use Discount (CUD)</name>
      <definition>A discount of up to 70% for committing to use a minimum amount of compute resources for 1 or 3 years.</definition>
      <exam-note>CUDs are regional and apply across projects; best for steady-state production workloads.</exam-note>
      <related-terms>
        <term-ref>Sustained Use Discount</term-ref>
        <term-ref>Spot VM</term-ref>
      </related-terms>
    </term>
    <term id="gl-sud" category="Cost Optimization">
      <name>Sustained Use Discount (SUD)</name>
      <definition>Automatic discounts up to 30% applied to VMs running for more than 25% of a month, with no commitment required.</definition>
      <exam-note>Applied automatically; E2 and A2 machine types do not receive SUDs.</exam-note>
      <related-terms>
        <term-ref>Committed Use Discount</term-ref>
      </related-terms>
    </term>
    <term id="gl-tpu" category="Hardware Accelerators">
      <name>Tensor Processing Unit (TPU)</name>
      <definition>Google's custom-built ASIC designed to accelerate machine learning workloads, especially for TensorFlow and JAX models.</definition>
      <exam-note>TPU pods can scale to thousands of chips for distributed training of large models.</exam-note>
      <related-terms>
        <term-ref>GPU</term-ref>
        <term-ref>Machine Learning</term-ref>
      </related-terms>
    </term>
    <term id="gl-gpu" category="Hardware Accelerators">
      <name>Graphics Processing Unit (GPU)</name>
      <definition>Hardware accelerators attached to VMs for parallel processing workloads like ML training, rendering, and scientific computing.</definition>
      <exam-note>Available on N1, A2, and G2 machine types; requires driver installation.</exam-note>
      <related-terms>
        <term-ref>TPU</term-ref>
        <term-ref>A2 Machine Type</term-ref>
      </related-terms>
    </term>
    <term id="gl-persistent-disk" category="Storage">
      <name>Persistent Disk</name>
      <definition>Durable network-attached block storage for Compute Engine VMs that persists independently of VM lifecycle.</definition>
      <exam-note>Types include pd-standard, pd-balanced, pd-ssd, and pd-extreme; supports snapshots and resizing.</exam-note>
      <related-terms>
        <term-ref>Local SSD</term-ref>
        <term-ref>Compute Engine</term-ref>
      </related-terms>
    </term>
    <term id="gl-local-ssd" category="Storage">
      <name>Local SSD</name>
      <definition>High-performance, physically attached storage that provides very low latency but data is ephemeral (lost when VM stops).</definition>
      <exam-note>Use for caches and scratch data; cannot be detached or snapshotted.</exam-note>
      <related-terms>
        <term-ref>Persistent Disk</term-ref>
      </related-terms>
    </term>
    <term id="gl-instance-template" category="Configuration">
      <name>Instance Template</name>
      <definition>A resource that defines VM properties (machine type, disk, network, metadata) used by managed instance groups to create identical instances.</definition>
      <exam-note>Templates are immutable; create new versions and update MIGs with rolling updates.</exam-note>
      <related-terms>
        <term-ref>MIG</term-ref>
        <term-ref>Machine Image</term-ref>
      </related-terms>
    </term>
    <term id="gl-workload-identity" category="Security">
      <name>Workload Identity</name>
      <definition>The recommended way to authenticate GKE workloads to Google Cloud APIs by linking Kubernetes service accounts to GCP IAM service accounts.</definition>
      <exam-note>Eliminates need for service account keys; provides automatic credential rotation.</exam-note>
      <related-terms>
        <term-ref>GKE</term-ref>
        <term-ref>IAM</term-ref>
      </related-terms>
    </term>
  </glossary>
</certification-exam>