<?xml version='1.0' encoding='UTF-8'?>
<certification-exam xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="../schema/certification.xsd" version="1.0">
  <metadata>
    <exam-code>DP-900</exam-code>
    <exam-title>Microsoft Azure Data Fundamentals</exam-title>
    <provider>Microsoft</provider>
    <description>Validate foundational knowledge of core data concepts and Azure data services including relational and non-relational data, analytics workloads, and data processing.</description>
    <total-questions>50</total-questions>
    <last-updated>2026-01-20</last-updated>
    <created-date>2026-01-20</created-date>
    <categories>
      <category id="cat-core-data">Core Data Concepts</category>
      <category id="cat-relational">Relational Data in Azure</category>
      <category id="cat-non-relational">Non-Relational Data in Azure</category>
      <category id="cat-analytics">Analytics Workloads in Azure</category>
    </categories>
  </metadata>

  <questions>
    
    <question id="dp900-q001">
      <category-ref>cat-core-data</category-ref>
      <difficulty>basic</difficulty>
      <title>Understanding Structured Data</title>
      <scenario>A retail company stores product information including product ID, name, price, and category. Each product record follows the same format with consistent fields. The data is stored in tables with defined columns and relationships between products and categories.</scenario>
      <question-text>What type of data best describes how this company stores its product information?</question-text>
      <choices>
        <choice id="A">Structured data</choice>
        <choice id="B">Unstructured data</choice>
        <choice id="C">Semi-structured data</choice>
        <choice id="D">Binary data</choice>
      </choices>
      <correct-answer>A</correct-answer>
      <hints>
        <hint level="1">Consider whether the data follows a fixed schema with defined columns.</hint>
        <hint level="2">Data stored in tables with rows and columns where each field has a specific data type is a particular classification.</hint>
        <hint level="3">Structured data is organized in a tabular format with a predefined schema, making it ideal for relational databases.</hint>
      </hints>
      <tags>
        <tag>data-types</tag>
        <tag>structured-data</tag>
        <tag>fundamentals</tag>
      </tags>
    </question>

    <question id="dp900-q002">
      <category-ref>cat-core-data</category-ref>
      <difficulty>basic</difficulty>
      <title>Semi-Structured Data Identification</title>
      <scenario>A web application stores user profile data in JSON format. Each user document contains fields like name, email, and preferences, but the preferences field can contain different sub-fields for different users. Some users have notification preferences while others have display preferences.</scenario>
      <question-text>What type of data classification best describes this user profile storage approach?</question-text>
      <choices>
        <choice id="A">Structured data</choice>
        <choice id="B">Semi-structured data</choice>
        <choice id="C">Unstructured data</choice>
        <choice id="D">Transactional data</choice>
      </choices>
      <correct-answer>B</correct-answer>
      <hints>
        <hint level="1">Consider that JSON has tags or markers but doesn't enforce a rigid schema.</hint>
        <hint level="2">This type of data has some organizational properties but doesn't conform to a fixed tabular structure.</hint>
        <hint level="3">Semi-structured data like JSON or XML contains tags and markers to separate elements but allows flexibility in the schema.</hint>
      </hints>
      <tags>
        <tag>data-types</tag>
        <tag>semi-structured</tag>
        <tag>json</tag>
      </tags>
    </question>

    <question id="dp900-q003">
      <category-ref>cat-core-data</category-ref>
      <difficulty>basic</difficulty>
      <title>Unstructured Data Example</title>
      <scenario>A media company stores thousands of video files, audio recordings, and images from various events. These files don't follow any specific format for their content and vary in size, resolution, and encoding.</scenario>
      <question-text>What type of data classification best describes these media files?</question-text>
      <choices>
        <choice id="A">Unstructured data</choice>
        <choice id="B">Semi-structured data</choice>
        <choice id="C">Relational data</choice>
        <choice id="D">Structured data</choice>
      </choices>
      <correct-answer>A</correct-answer>
      <hints>
        <hint level="1">Consider whether video and audio content has a predefined schema or format.</hint>
        <hint level="2">Media files like videos, images, and audio don't conform to tables or hierarchical formats.</hint>
        <hint level="3">Unstructured data includes files like documents, images, videos, and audio that don't have a predefined data model.</hint>
      </hints>
      <tags>
        <tag>data-types</tag>
        <tag>unstructured</tag>
        <tag>media</tag>
      </tags>
    </question>

    <question id="dp900-q004">
      <category-ref>cat-core-data</category-ref>
      <difficulty>basic</difficulty>
      <title>OLTP Workload Characteristics</title>
      <scenario>An e-commerce website processes thousands of orders per hour. Each transaction involves inserting a new order record, updating inventory levels, and recording payment information. The system needs to handle many concurrent users making quick, small updates to the database.</scenario>
      <question-text>What type of data processing workload does this scenario describe?</question-text>
      <choices>
        <choice id="A">OLAP (Online Analytical Processing)</choice>
        <choice id="B">Batch processing</choice>
        <choice id="C">OLTP (Online Transaction Processing)</choice>
        <choice id="D">Stream processing</choice>
      </choices>
      <correct-answer>C</correct-answer>
      <hints>
        <hint level="1">Consider the nature of the operations: many small, quick updates from concurrent users.</hint>
        <hint level="2">This workload focuses on recording and processing business transactions in real-time.</hint>
        <hint level="3">OLTP systems are optimized for processing high volumes of small transactions with low latency, like order processing.</hint>
      </hints>
      <tags>
        <tag>oltp</tag>
        <tag>workloads</tag>
        <tag>transactions</tag>
      </tags>
    </question>

    <question id="dp900-q005">
      <category-ref>cat-core-data</category-ref>
      <difficulty>basic</difficulty>
      <title>OLAP Workload Characteristics</title>
      <scenario>A business intelligence team runs complex queries against historical sales data spanning five years. They analyze trends, calculate aggregations across multiple dimensions like time, region, and product category, and generate reports for executive decision-making.</scenario>
      <question-text>What type of data processing workload does this scenario describe?</question-text>
      <choices>
        <choice id="A">OLTP (Online Transaction Processing)</choice>
        <choice id="B">OLAP (Online Analytical Processing)</choice>
        <choice id="C">Real-time processing</choice>
        <choice id="D">Data ingestion</choice>
      </choices>
      <correct-answer>B</correct-answer>
      <hints>
        <hint level="1">Consider the focus on historical data analysis and complex queries.</hint>
        <hint level="2">This workload emphasizes reading and analyzing large volumes of data rather than writing transactions.</hint>
        <hint level="3">OLAP systems are optimized for complex analytical queries, aggregations, and historical trend analysis.</hint>
      </hints>
      <tags>
        <tag>olap</tag>
        <tag>analytics</tag>
        <tag>business-intelligence</tag>
      </tags>
    </question>

    <question id="dp900-q006">
      <category-ref>cat-core-data</category-ref>
      <difficulty>intermediate</difficulty>
      <title>Batch vs Stream Processing</title>
      <scenario>A logistics company needs to process GPS data from its delivery trucks. They want to display the current location of each truck on a real-time dashboard and alert dispatchers immediately when a truck deviates from its planned route.</scenario>
      <question-text>Which data processing approach is most appropriate for this requirement?</question-text>
      <choices>
        <choice id="A">Batch processing with daily aggregation</choice>
        <choice id="B">ETL with nightly data loads</choice>
        <choice id="C">OLAP with weekly reporting</choice>
        <choice id="D">Stream processing with real-time analysis</choice>
      </choices>
      <correct-answer>D</correct-answer>
      <hints>
        <hint level="1">Consider the requirement for real-time dashboards and immediate alerts.</hint>
        <hint level="2">Processing data as it arrives rather than in scheduled batches addresses the immediacy requirement.</hint>
        <hint level="3">Stream processing analyzes data in real-time as it's generated, enabling immediate insights and alerts.</hint>
      </hints>
      <tags>
        <tag>stream-processing</tag>
        <tag>real-time</tag>
        <tag>data-processing</tag>
      </tags>
    </question>

    <question id="dp900-q007">
      <category-ref>cat-core-data</category-ref>
      <difficulty>basic</difficulty>
      <title>Data Professional Roles</title>
      <scenario>A company needs to hire someone who will design and implement data storage solutions, set up data pipelines to move data between systems, and ensure data is available and secure for other teams to use.</scenario>
      <question-text>Which data professional role best matches these responsibilities?</question-text>
      <choices>
        <choice id="A">Data Analyst</choice>
        <choice id="B">Data Scientist</choice>
        <choice id="C">Data Engineer</choice>
        <choice id="D">Database Administrator</choice>
      </choices>
      <correct-answer>C</correct-answer>
      <hints>
        <hint level="1">Consider who is responsible for building and maintaining data infrastructure.</hint>
        <hint level="2">This role focuses on data pipelines, storage solutions, and making data available to others.</hint>
        <hint level="3">Data Engineers design and build systems for collecting, storing, and analyzing data at scale.</hint>
      </hints>
      <tags>
        <tag>roles</tag>
        <tag>data-engineer</tag>
        <tag>fundamentals</tag>
      </tags>
    </question>

    <question id="dp900-q008">
      <category-ref>cat-core-data</category-ref>
      <difficulty>basic</difficulty>
      <title>Data Analyst Role</title>
      <scenario>A team member creates visualizations and reports from sales data, explores data to find trends and patterns, and presents findings to business stakeholders to help them make informed decisions.</scenario>
      <question-text>Which data professional role best describes these activities?</question-text>
      <choices>
        <choice id="A">Data Analyst</choice>
        <choice id="B">Data Engineer</choice>
        <choice id="C">Data Scientist</choice>
        <choice id="D">Database Administrator</choice>
      </choices>
      <correct-answer>A</correct-answer>
      <hints>
        <hint level="1">Consider who transforms data into insights through visualization and reporting.</hint>
        <hint level="2">This role focuses on exploring existing data and communicating findings to stakeholders.</hint>
        <hint level="3">Data Analysts explore and analyze data to create visualizations and reports that drive business decisions.</hint>
      </hints>
      <tags>
        <tag>roles</tag>
        <tag>data-analyst</tag>
        <tag>fundamentals</tag>
      </tags>
    </question>

    <question id="dp900-q009">
      <category-ref>cat-core-data</category-ref>
      <difficulty>intermediate</difficulty>
      <title>ETL Process Understanding</title>
      <scenario>A company needs to combine customer data from multiple source systems into a data warehouse. The process involves reading data from source systems, converting date formats, standardizing address fields, removing duplicates, and loading the cleansed data into the destination.</scenario>
      <question-text>What data integration process is being described?</question-text>
      <choices>
        <choice id="A">Data replication</choice>
        <choice id="B">ETL (Extract, Transform, Load)</choice>
        <choice id="C">Data virtualization</choice>
        <choice id="D">Database mirroring</choice>
      </choices>
      <correct-answer>B</correct-answer>
      <hints>
        <hint level="1">Consider the three main steps: reading from source, modifying data, and writing to destination.</hint>
        <hint level="2">This process extracts data, applies transformations, and loads it into a target system.</hint>
        <hint level="3">ETL stands for Extract, Transform, Load - a process that moves and transforms data between systems.</hint>
      </hints>
      <tags>
        <tag>etl</tag>
        <tag>data-integration</tag>
        <tag>data-processing</tag>
      </tags>
    </question>

    <question id="dp900-q010">
      <category-ref>cat-core-data</category-ref>
      <difficulty>intermediate</difficulty>
      <title>Data Normalization Purpose</title>
      <scenario>A database designer is restructuring a customer database. Currently, customer address information is duplicated across multiple order records. The designer plans to create a separate address table and link it to customers using a foreign key to eliminate this redundancy.</scenario>
      <question-text>What database design principle is the designer applying?</question-text>
      <choices>
        <choice id="A">Denormalization</choice>
        <choice id="B">Partitioning</choice>
        <choice id="C">Normalization</choice>
        <choice id="D">Sharding</choice>
      </choices>
      <correct-answer>C</correct-answer>
      <hints>
        <hint level="1">Consider the goal of eliminating data redundancy through table restructuring.</hint>
        <hint level="2">This process organizes data to reduce duplication and improve data integrity.</hint>
        <hint level="3">Normalization is the process of organizing data to minimize redundancy by dividing data into related tables.</hint>
      </hints>
      <tags>
        <tag>normalization</tag>
        <tag>database-design</tag>
        <tag>relational</tag>
      </tags>
    </question>

    <question id="dp900-q011">
      <category-ref>cat-core-data</category-ref>
      <difficulty>basic</difficulty>
      <title>Primary Key Purpose</title>
      <scenario>A database table stores employee records. Each employee must be uniquely identifiable, and no two employees can share the same identifier. The identifier cannot be null and is used to link employee records to other tables like payroll and department assignments.</scenario>
      <question-text>What database concept ensures each employee record is uniquely identifiable?</question-text>
      <choices>
        <choice id="A">Foreign key</choice>
        <choice id="B">Index</choice>
        <choice id="C">Primary key</choice>
        <choice id="D">Constraint</choice>
      </choices>
      <correct-answer>C</correct-answer>
      <hints>
        <hint level="1">Consider which key type uniquely identifies each record in a table.</hint>
        <hint level="2">This key cannot be null and must be unique for every record.</hint>
        <hint level="3">A primary key is a column or combination of columns that uniquely identifies each row in a table.</hint>
      </hints>
      <tags>
        <tag>primary-key</tag>
        <tag>database-design</tag>
        <tag>relational</tag>
      </tags>
    </question>

    <question id="dp900-q012">
      <category-ref>cat-core-data</category-ref>
      <difficulty>intermediate</difficulty>
      <title>Foreign Key Relationships</title>
      <scenario>An order management database has an Orders table and a Customers table. Each order record must reference a valid customer. The database should prevent orders from being created for non-existent customers and prevent customer deletion if they have existing orders.</scenario>
      <question-text>What database concept enforces this referential integrity between Orders and Customers?</question-text>
      <choices>
        <choice id="A">Primary key</choice>
        <choice id="B">Unique constraint</choice>
        <choice id="C">Foreign key</choice>
        <choice id="D">Check constraint</choice>
      </choices>
      <correct-answer>C</correct-answer>
      <hints>
        <hint level="1">Consider which key type creates relationships between tables.</hint>
        <hint level="2">This key references the primary key of another table to enforce referential integrity.</hint>
        <hint level="3">A foreign key is a column that references the primary key of another table, enforcing referential integrity.</hint>
      </hints>
      <tags>
        <tag>foreign-key</tag>
        <tag>referential-integrity</tag>
        <tag>relational</tag>
      </tags>
    </question>

    
    <question id="dp900-q013">
      <category-ref>cat-relational</category-ref>
      <difficulty>basic</difficulty>
      <title>Azure SQL Database Overview</title>
      <scenario>A startup is building a new web application and needs a relational database. They want a fully managed service where Microsoft handles patching, backups, and high availability. They don't want to manage any virtual machines or operating systems.</scenario>
      <question-text>Which Azure service best meets their requirements for a managed relational database?</question-text>
      <choices>
        <choice id="A">Azure SQL Database</choice>
        <choice id="B">SQL Server on Azure Virtual Machines</choice>
        <choice id="C">Azure Table Storage</choice>
        <choice id="D">Azure Cosmos DB</choice>
      </choices>
      <correct-answer>A</correct-answer>
      <hints>
        <hint level="1">Consider which service is a PaaS offering for relational databases.</hint>
        <hint level="2">This service provides automatic patching, backups, and high availability without VM management.</hint>
        <hint level="3">Azure SQL Database is a fully managed PaaS relational database with built-in intelligence and high availability.</hint>
      </hints>
      <tags>
        <tag>azure-sql</tag>
        <tag>paas</tag>
        <tag>managed-service</tag>
      </tags>
    </question>

    <question id="dp900-q014">
      <category-ref>cat-relational</category-ref>
      <difficulty>intermediate</difficulty>
      <title>Azure SQL Managed Instance Use Case</title>
      <scenario>A company is migrating an on-premises SQL Server database to Azure. The database uses SQL Server Agent jobs, cross-database queries, and CLR functions. They need near 100% compatibility with their existing SQL Server features while still benefiting from a managed service.</scenario>
      <question-text>Which Azure service provides the best compatibility for this migration?</question-text>
      <choices>
        <choice id="A">Azure SQL Database single database</choice>
        <choice id="B">Azure Synapse Analytics</choice>
        <choice id="C">Azure Database for MySQL</choice>
        <choice id="D">Azure SQL Managed Instance</choice>
      </choices>
      <correct-answer>D</correct-answer>
      <hints>
        <hint level="1">Consider which service offers the highest SQL Server compatibility as a managed service.</hint>
        <hint level="2">This service supports SQL Server Agent, cross-database queries, and CLR integration.</hint>
        <hint level="3">Azure SQL Managed Instance provides near 100% SQL Server compatibility with PaaS benefits.</hint>
      </hints>
      <tags>
        <tag>sql-managed-instance</tag>
        <tag>migration</tag>
        <tag>compatibility</tag>
      </tags>
    </question>

    <question id="dp900-q015">
      <category-ref>cat-relational</category-ref>
      <difficulty>basic</difficulty>
      <title>Azure Database for PostgreSQL</title>
      <scenario>A development team has built their application using PostgreSQL. They want to move to Azure but continue using PostgreSQL as their database engine. They need a managed service that handles backups, patching, and provides high availability.</scenario>
      <question-text>Which Azure service should they use?</question-text>
      <choices>
        <choice id="A">Azure Database for PostgreSQL</choice>
        <choice id="B">Azure SQL Database</choice>
        <choice id="C">Azure Cosmos DB</choice>
        <choice id="D">Azure SQL Managed Instance</choice>
      </choices>
      <correct-answer>A</correct-answer>
      <hints>
        <hint level="1">Consider which Azure service is specifically designed for PostgreSQL workloads.</hint>
        <hint level="2">Azure offers managed services for various open-source database engines.</hint>
        <hint level="3">Azure Database for PostgreSQL is a fully managed PostgreSQL database service.</hint>
      </hints>
      <tags>
        <tag>postgresql</tag>
        <tag>open-source</tag>
        <tag>managed-service</tag>
      </tags>
    </question>

    <question id="dp900-q016">
      <category-ref>cat-relational</category-ref>
      <difficulty>basic</difficulty>
      <title>Azure Database for MySQL</title>
      <scenario>A company runs a popular WordPress site backed by MySQL. They want to migrate to Azure for better scalability and reduced management overhead while keeping MySQL as their database engine.</scenario>
      <question-text>Which Azure service should they use for their MySQL database?</question-text>
      <choices>
        <choice id="A">Azure SQL Database</choice>
        <choice id="B">Azure Database for MySQL</choice>
        <choice id="C">Azure Database for MariaDB</choice>
        <choice id="D">Azure Cosmos DB</choice>
      </choices>
      <correct-answer>B</correct-answer>
      <hints>
        <hint level="1">Consider which Azure service is specifically designed for MySQL workloads.</hint>
        <hint level="2">Azure provides managed services for popular open-source database engines.</hint>
        <hint level="3">Azure Database for MySQL is a fully managed MySQL database service with enterprise-grade security.</hint>
      </hints>
      <tags>
        <tag>mysql</tag>
        <tag>open-source</tag>
        <tag>managed-service</tag>
      </tags>
    </question>

    <question id="dp900-q017">
      <category-ref>cat-relational</category-ref>
      <difficulty>intermediate</difficulty>
      <title>SQL Query - SELECT Statement</title>
      <scenario>A data analyst needs to retrieve all customer names and email addresses from a Customers table where the customer is located in the 'West' region. They only want these two columns, not all columns from the table.</scenario>
      <question-text>Which SQL statement correctly retrieves this data?</question-text>
      <choices>
        <choice id="A">SELECT * FROM Customers WHERE Region = 'West'</choice>
        <choice id="B">RETRIEVE CustomerName, Email FROM Customers WHEN Region = 'West'</choice>
        <choice id="C">GET CustomerName, Email FROM Customers IF Region = 'West'</choice>
        <choice id="D">SELECT CustomerName, Email FROM Customers WHERE Region = 'West'</choice>
      </choices>
      <correct-answer>D</correct-answer>
      <hints>
        <hint level="1">Consider the standard SQL syntax for selecting specific columns with a filter condition.</hint>
        <hint level="2">SELECT specifies columns, FROM specifies the table, and WHERE specifies the filter.</hint>
        <hint level="3">SELECT column1, column2 FROM table WHERE condition is the correct SQL syntax.</hint>
      </hints>
      <tags>
        <tag>sql</tag>
        <tag>select</tag>
        <tag>query</tag>
      </tags>
    </question>

    <question id="dp900-q018">
      <category-ref>cat-relational</category-ref>
      <difficulty>intermediate</difficulty>
      <title>SQL JOIN Operations</title>
      <scenario>A report needs to show order information along with customer details. The Orders table contains OrderID, CustomerID, and OrderDate. The Customers table contains CustomerID, CustomerName, and Email. A query must combine data from both tables based on matching CustomerID values.</scenario>
      <question-text>Which SQL operation combines data from these two tables?</question-text>
      <choices>
        <choice id="A">UNION</choice>
        <choice id="B">COMBINE</choice>
        <choice id="C">MERGE</choice>
        <choice id="D">JOIN</choice>
      </choices>
      <correct-answer>D</correct-answer>
      <hints>
        <hint level="1">Consider which SQL operation links rows from multiple tables based on related columns.</hint>
        <hint level="2">This operation matches rows from different tables using a common key.</hint>
        <hint level="3">JOIN combines rows from two or more tables based on a related column between them.</hint>
      </hints>
      <tags>
        <tag>sql</tag>
        <tag>join</tag>
        <tag>query</tag>
      </tags>
    </question>

    <question id="dp900-q019">
      <category-ref>cat-relational</category-ref>
      <difficulty>intermediate</difficulty>
      <title>SQL Aggregation Functions</title>
      <scenario>A sales manager wants to know the total revenue generated from all orders in the Orders table. The table has an OrderAmount column containing the value of each order. They need a single sum of all order amounts.</scenario>
      <question-text>Which SQL function calculates the total of all OrderAmount values?</question-text>
      <choices>
        <choice id="A">COUNT(OrderAmount)</choice>
        <choice id="B">SUM(OrderAmount)</choice>
        <choice id="C">AVG(OrderAmount)</choice>
        <choice id="D">TOTAL(OrderAmount)</choice>
      </choices>
      <correct-answer>B</correct-answer>
      <hints>
        <hint level="1">Consider which aggregate function adds up numeric values.</hint>
        <hint level="2">COUNT counts rows, AVG calculates average, but another function calculates the total.</hint>
        <hint level="3">SUM() is the aggregate function that calculates the total of numeric values.</hint>
      </hints>
      <tags>
        <tag>sql</tag>
        <tag>aggregation</tag>
        <tag>sum</tag>
      </tags>
    </question>

    <question id="dp900-q020">
      <category-ref>cat-relational</category-ref>
      <difficulty>basic</difficulty>
      <title>SQL INSERT Statement</title>
      <scenario>An application needs to add a new customer record to the Customers table. The table has columns for CustomerID, CustomerName, and Email. The application must insert values for all three columns.</scenario>
      <question-text>Which SQL statement type is used to add new records to a table?</question-text>
      <choices>
        <choice id="A">INSERT</choice>
        <choice id="B">UPDATE</choice>
        <choice id="C">SELECT</choice>
        <choice id="D">CREATE</choice>
      </choices>
      <correct-answer>A</correct-answer>
      <hints>
        <hint level="1">Consider which SQL statement adds new rows to a table.</hint>
        <hint level="2">SELECT reads data, UPDATE modifies existing data, but another statement creates new records.</hint>
        <hint level="3">INSERT is the SQL statement used to add new rows to a table.</hint>
      </hints>
      <tags>
        <tag>sql</tag>
        <tag>insert</tag>
        <tag>dml</tag>
      </tags>
    </question>

    <question id="dp900-q021">
      <category-ref>cat-relational</category-ref>
      <difficulty>basic</difficulty>
      <title>SQL UPDATE Statement</title>
      <scenario>A customer has changed their email address and the database needs to be updated. The Customers table contains their record with CustomerID 1001. Only the Email column needs to be modified for this specific customer.</scenario>
      <question-text>Which SQL statement type modifies existing records in a table?</question-text>
      <choices>
        <choice id="A">INSERT</choice>
        <choice id="B">UPDATE</choice>
        <choice id="C">ALTER</choice>
        <choice id="D">MODIFY</choice>
      </choices>
      <correct-answer>B</correct-answer>
      <hints>
        <hint level="1">Consider which SQL statement changes values in existing rows.</hint>
        <hint level="2">INSERT adds new rows, ALTER changes table structure, but another statement modifies data.</hint>
        <hint level="3">UPDATE is the SQL statement used to modify existing data in a table.</hint>
      </hints>
      <tags>
        <tag>sql</tag>
        <tag>update</tag>
        <tag>dml</tag>
      </tags>
    </question>

    <question id="dp900-q022">
      <category-ref>cat-relational</category-ref>
      <difficulty>basic</difficulty>
      <title>SQL DELETE Statement</title>
      <scenario>A company needs to remove all order records older than 7 years from their Orders table to comply with data retention policies. The records should be permanently removed from the database.</scenario>
      <question-text>Which SQL statement type removes records from a table?</question-text>
      <choices>
        <choice id="A">DROP</choice>
        <choice id="B">REMOVE</choice>
        <choice id="C">DELETE</choice>
        <choice id="D">TRUNCATE</choice>
      </choices>
      <correct-answer>C</correct-answer>
      <hints>
        <hint level="1">Consider which SQL statement removes specific rows based on a condition.</hint>
        <hint level="2">DROP removes entire tables, TRUNCATE removes all rows, but another allows conditional removal.</hint>
        <hint level="3">DELETE removes specific rows from a table, optionally filtered by a WHERE clause.</hint>
      </hints>
      <tags>
        <tag>sql</tag>
        <tag>delete</tag>
        <tag>dml</tag>
      </tags>
    </question>

    <question id="dp900-q023">
      <category-ref>cat-relational</category-ref>
      <difficulty>intermediate</difficulty>
      <title>Database Views</title>
      <scenario>A database administrator needs to provide a simplified way for analysts to query order data combined with customer information. They want to create a virtual table that always shows current data from the underlying Orders and Customers tables without duplicating storage.</scenario>
      <question-text>What database object should be created to meet this requirement?</question-text>
      <choices>
        <choice id="A">Stored procedure</choice>
        <choice id="B">Temporary table</choice>
        <choice id="C">View</choice>
        <choice id="D">Index</choice>
      </choices>
      <correct-answer>C</correct-answer>
      <hints>
        <hint level="1">Consider which database object provides a virtual table based on a query.</hint>
        <hint level="2">This object stores a query definition but not the data itself.</hint>
        <hint level="3">A view is a virtual table based on a SELECT statement that provides a simplified way to access data.</hint>
      </hints>
      <tags>
        <tag>views</tag>
        <tag>database-objects</tag>
        <tag>sql</tag>
      </tags>
    </question>

    <question id="dp900-q024">
      <category-ref>cat-relational</category-ref>
      <difficulty>intermediate</difficulty>
      <title>Stored Procedures</title>
      <scenario>A development team wants to encapsulate complex business logic for processing customer orders. The logic includes multiple SQL statements, conditional branching, and should be reusable across different applications. They want to improve security by limiting direct table access.</scenario>
      <question-text>What database object should be used to encapsulate this reusable business logic?</question-text>
      <choices>
        <choice id="A">View</choice>
        <choice id="B">Stored procedure</choice>
        <choice id="C">Trigger</choice>
        <choice id="D">Function</choice>
      </choices>
      <correct-answer>B</correct-answer>
      <hints>
        <hint level="1">Consider which database object can contain multiple SQL statements and programming logic.</hint>
        <hint level="2">This object is compiled and stored in the database for repeated execution.</hint>
        <hint level="3">A stored procedure is a precompiled collection of SQL statements and logic stored in the database.</hint>
      </hints>
      <tags>
        <tag>stored-procedures</tag>
        <tag>database-objects</tag>
        <tag>sql</tag>
      </tags>
    </question>

    <question id="dp900-q025">
      <category-ref>cat-relational</category-ref>
      <difficulty>intermediate</difficulty>
      <title>Database Indexes</title>
      <scenario>A query that searches for customers by their email address is running slowly because the Customers table has millions of rows. The database needs to find matching rows faster without scanning every row in the table.</scenario>
      <question-text>What database object can improve the query performance for searching by email?</question-text>
      <choices>
        <choice id="A">View</choice>
        <choice id="B">Stored procedure</choice>
        <choice id="C">Index</choice>
        <choice id="D">Constraint</choice>
      </choices>
      <correct-answer>C</correct-answer>
      <hints>
        <hint level="1">Consider which database object helps locate rows quickly without scanning the entire table.</hint>
        <hint level="2">This object creates a data structure that speeds up data retrieval operations.</hint>
        <hint level="3">An index is a data structure that improves query performance by enabling faster lookups.</hint>
      </hints>
      <tags>
        <tag>indexes</tag>
        <tag>performance</tag>
        <tag>database-objects</tag>
      </tags>
    </question>

    
    <question id="dp900-q026">
      <category-ref>cat-non-relational</category-ref>
      <difficulty>basic</difficulty>
      <title>Azure Cosmos DB Overview</title>
      <scenario>A global gaming company needs a database that can handle millions of player sessions with single-digit millisecond latency. The database must replicate data across multiple regions for low-latency access worldwide and support multiple data models including document and key-value.</scenario>
      <question-text>Which Azure service best meets these requirements?</question-text>
      <choices>
        <choice id="A">Azure SQL Database</choice>
        <choice id="B">Azure Database for PostgreSQL</choice>
        <choice id="C">Azure Table Storage</choice>
        <choice id="D">Azure Cosmos DB</choice>
      </choices>
      <correct-answer>D</correct-answer>
      <hints>
        <hint level="1">Consider which Azure service is designed for global distribution and multiple data models.</hint>
        <hint level="2">This service offers guaranteed low latency and turnkey global replication.</hint>
        <hint level="3">Azure Cosmos DB is a globally distributed, multi-model database with guaranteed low latency.</hint>
      </hints>
      <tags>
        <tag>cosmos-db</tag>
        <tag>nosql</tag>
        <tag>global-distribution</tag>
      </tags>
    </question>

    <question id="dp900-q027">
      <category-ref>cat-non-relational</category-ref>
      <difficulty>intermediate</difficulty>
      <title>Cosmos DB API Selection</title>
      <scenario>A team is building an application that stores product catalog data as JSON documents. They want to use familiar MongoDB query syntax and drivers because their developers have extensive MongoDB experience. They also want the benefits of Azure's managed services.</scenario>
      <question-text>Which Azure Cosmos DB API should they choose?</question-text>
      <choices>
        <choice id="A">API for NoSQL</choice>
        <choice id="B">API for Table</choice>
        <choice id="C">API for Apache Cassandra</choice>
        <choice id="D">API for MongoDB</choice>
      </choices>
      <correct-answer>D</correct-answer>
      <hints>
        <hint level="1">Consider which API provides MongoDB compatibility.</hint>
        <hint level="2">Cosmos DB supports multiple APIs including one for MongoDB-compatible applications.</hint>
        <hint level="3">The API for MongoDB allows existing MongoDB applications to work with Cosmos DB using MongoDB drivers.</hint>
      </hints>
      <tags>
        <tag>cosmos-db</tag>
        <tag>mongodb</tag>
        <tag>api</tag>
      </tags>
    </question>

    <question id="dp900-q028">
      <category-ref>cat-non-relational</category-ref>
      <difficulty>basic</difficulty>
      <title>Azure Blob Storage Overview</title>
      <scenario>A media company needs to store large video files, images, and documents in Azure. The files range from a few megabytes to several gigabytes. They need a cost-effective solution for storing unstructured data that can scale to petabytes.</scenario>
      <question-text>Which Azure service is designed for storing this type of unstructured data?</question-text>
      <choices>
        <choice id="A">Azure Blob Storage</choice>
        <choice id="B">Azure SQL Database</choice>
        <choice id="C">Azure Table Storage</choice>
        <choice id="D">Azure Files</choice>
      </choices>
      <correct-answer>A</correct-answer>
      <hints>
        <hint level="1">Consider which Azure storage service is optimized for unstructured data like files.</hint>
        <hint level="2">This service stores binary large objects (blobs) of any type and size.</hint>
        <hint level="3">Azure Blob Storage is Microsoft's object storage solution for unstructured data like files, images, and videos.</hint>
      </hints>
      <tags>
        <tag>blob-storage</tag>
        <tag>unstructured</tag>
        <tag>object-storage</tag>
      </tags>
    </question>

    <question id="dp900-q029">
      <category-ref>cat-non-relational</category-ref>
      <difficulty>intermediate</difficulty>
      <title>Blob Storage Access Tiers</title>
      <scenario>A company stores compliance documents that must be retained for 7 years. These documents are rarely accessed after the first 30 days but must be kept for legal requirements. They want to minimize storage costs for the long-term retention period.</scenario>
      <question-text>Which Azure Blob Storage access tier is most cost-effective for rarely accessed data with long retention requirements?</question-text>
      <choices>
        <choice id="A">Hot tier</choice>
        <choice id="B">Archive tier</choice>
        <choice id="C">Cool tier</choice>
        <choice id="D">Premium tier</choice>
      </choices>
      <correct-answer>B</correct-answer>
      <hints>
        <hint level="1">Consider which tier has the lowest storage costs but higher access costs.</hint>
        <hint level="2">This tier is designed for data that is rarely accessed and stored for long periods.</hint>
        <hint level="3">The Archive tier offers the lowest storage costs for data that can tolerate hours of retrieval latency.</hint>
      </hints>
      <tags>
        <tag>blob-storage</tag>
        <tag>access-tiers</tag>
        <tag>cost-optimization</tag>
      </tags>
    </question>

    <question id="dp900-q030">
      <category-ref>cat-non-relational</category-ref>
      <difficulty>basic</difficulty>
      <title>Azure Files Overview</title>
      <scenario>A company needs to migrate their on-premises file shares to Azure. They have applications that use SMB protocol to access shared folders. The solution must support mounting as a network drive on Windows, Linux, and macOS.</scenario>
      <question-text>Which Azure service provides managed file shares accessible via SMB protocol?</question-text>
      <choices>
        <choice id="A">Azure Blob Storage</choice>
        <choice id="B">Azure Files</choice>
        <choice id="C">Azure Disk Storage</choice>
        <choice id="D">Azure Data Lake Storage</choice>
      </choices>
      <correct-answer>B</correct-answer>
      <hints>
        <hint level="1">Consider which Azure service provides traditional file share functionality.</hint>
        <hint level="2">This service supports SMB protocol and can be mounted as a network drive.</hint>
        <hint level="3">Azure Files provides fully managed file shares accessible via SMB and NFS protocols.</hint>
      </hints>
      <tags>
        <tag>azure-files</tag>
        <tag>smb</tag>
        <tag>file-shares</tag>
      </tags>
    </question>

    <question id="dp900-q031">
      <category-ref>cat-non-relational</category-ref>
      <difficulty>intermediate</difficulty>
      <title>Azure Table Storage</title>
      <scenario>An IoT application needs to store billions of log entries from sensors. Each entry is small, containing sensor ID, timestamp, and a few metric values. The application needs fast key-value lookups but doesn't require complex queries or relationships between entries.</scenario>
      <question-text>Which Azure service provides cost-effective storage for this high-volume key-value data?</question-text>
      <choices>
        <choice id="A">Azure SQL Database</choice>
        <choice id="B">Azure Cosmos DB for NoSQL</choice>
        <choice id="C">Azure Table Storage</choice>
        <choice id="D">Azure Cache for Redis</choice>
      </choices>
      <correct-answer>C</correct-answer>
      <hints>
        <hint level="1">Consider which service is optimized for large-scale, simple key-value data.</hint>
        <hint level="2">This service offers schemaless storage with partition and row key access patterns.</hint>
        <hint level="3">Azure Table Storage provides cost-effective NoSQL key-value storage for large volumes of structured data.</hint>
      </hints>
      <tags>
        <tag>table-storage</tag>
        <tag>key-value</tag>
        <tag>nosql</tag>
      </tags>
    </question>

    <question id="dp900-q032">
      <category-ref>cat-non-relational</category-ref>
      <difficulty>intermediate</difficulty>
      <title>Document Database Concepts</title>
      <scenario>A content management system stores articles as individual documents. Each article has different fields - some have videos, some have image galleries, others have interactive elements. The system must query articles by various properties without a fixed schema.</scenario>
      <question-text>What type of NoSQL database model is best suited for this flexible document storage?</question-text>
      <choices>
        <choice id="A">Key-value store</choice>
        <choice id="B">Column-family database</choice>
        <choice id="C">Document database</choice>
        <choice id="D">Graph database</choice>
      </choices>
      <correct-answer>C</correct-answer>
      <hints>
        <hint level="1">Consider which database model stores self-describing records with flexible schemas.</hint>
        <hint level="2">This model stores data as documents (like JSON) that can have varying structures.</hint>
        <hint level="3">Document databases store data as self-contained documents with flexible schemas, ideal for varied content.</hint>
      </hints>
      <tags>
        <tag>document-database</tag>
        <tag>nosql</tag>
        <tag>schema-flexibility</tag>
      </tags>
    </question>

    <question id="dp900-q033">
      <category-ref>cat-non-relational</category-ref>
      <difficulty>intermediate</difficulty>
      <title>Graph Database Use Case</title>
      <scenario>A social networking platform needs to store user profiles and their connections. The key requirement is to efficiently query relationships like "friends of friends" or "people who follow users I follow" with complex traversal patterns across millions of connections.</scenario>
      <question-text>What type of NoSQL database model is best suited for relationship-heavy queries?</question-text>
      <choices>
        <choice id="A">Key-value store</choice>
        <choice id="B">Graph database</choice>
        <choice id="C">Column-family database</choice>
        <choice id="D">Document database</choice>
      </choices>
      <correct-answer>B</correct-answer>
      <hints>
        <hint level="1">Consider which database model is optimized for traversing relationships.</hint>
        <hint level="2">This model represents data as nodes and edges, making relationship queries efficient.</hint>
        <hint level="3">Graph databases use nodes and edges to represent and traverse relationships efficiently.</hint>
      </hints>
      <tags>
        <tag>graph-database</tag>
        <tag>nosql</tag>
        <tag>relationships</tag>
      </tags>
    </question>

    <question id="dp900-q034">
      <category-ref>cat-non-relational</category-ref>
      <difficulty>basic</difficulty>
      <title>Azure Data Lake Storage Gen2</title>
      <scenario>A data science team needs to store massive amounts of data for big data analytics. They need a storage solution that combines the scalability of blob storage with hierarchical namespace capabilities for efficient file operations and analytics processing.</scenario>
      <question-text>Which Azure service combines blob storage with hierarchical namespace for big data analytics?</question-text>
      <choices>
        <choice id="A">Azure Blob Storage</choice>
        <choice id="B">Azure Table Storage</choice>
        <choice id="C">Azure Files</choice>
        <choice id="D">Azure Data Lake Storage Gen2</choice>
      </choices>
      <correct-answer>D</correct-answer>
      <hints>
        <hint level="1">Consider which storage service is designed specifically for big data analytics workloads.</hint>
        <hint level="2">This service combines blob storage with a hierarchical file system namespace.</hint>
        <hint level="3">Azure Data Lake Storage Gen2 builds on Blob Storage with hierarchical namespace for analytics workloads.</hint>
      </hints>
      <tags>
        <tag>data-lake</tag>
        <tag>big-data</tag>
        <tag>analytics</tag>
      </tags>
    </question>

    <question id="dp900-q035">
      <category-ref>cat-non-relational</category-ref>
      <difficulty>intermediate</difficulty>
      <title>Cosmos DB Partition Key</title>
      <scenario>A developer is designing a Cosmos DB container to store customer orders. They need to choose a partition key that ensures even data distribution across partitions and supports the most common query patterns which filter by customer ID.</scenario>
      <question-text>What is the primary purpose of choosing an appropriate partition key in Cosmos DB?</question-text>
      <choices>
        <choice id="A">To encrypt data at rest</choice>
        <choice id="B">To enable global replication</choice>
        <choice id="C">To define primary key constraints</choice>
        <choice id="D">To distribute data evenly and optimize query performance</choice>
      </choices>
      <correct-answer>D</correct-answer>
      <hints>
        <hint level="1">Consider how partition keys affect data distribution and access patterns.</hint>
        <hint level="2">A good partition key ensures balanced data distribution and efficient queries.</hint>
        <hint level="3">Partition keys determine how data is distributed across physical partitions, affecting scalability and query performance.</hint>
      </hints>
      <tags>
        <tag>cosmos-db</tag>
        <tag>partitioning</tag>
        <tag>performance</tag>
      </tags>
    </question>

    <question id="dp900-q036">
      <category-ref>cat-non-relational</category-ref>
      <difficulty>intermediate</difficulty>
      <title>Cosmos DB Consistency Levels</title>
      <scenario>A financial application using Cosmos DB needs to ensure that after a write operation completes, all subsequent reads will return that written value. They cannot tolerate reading stale data even if it means higher latency.</scenario>
      <question-text>Which Cosmos DB consistency level guarantees that reads always return the most recent committed write?</question-text>
      <choices>
        <choice id="A">Eventual consistency</choice>
        <choice id="B">Session consistency</choice>
        <choice id="C">Strong consistency</choice>
        <choice id="D">Bounded staleness</choice>
      </choices>
      <correct-answer>C</correct-answer>
      <hints>
        <hint level="1">Consider which consistency level provides the strongest guarantee for read operations.</hint>
        <hint level="2">This level ensures linearizability - reads reflect the most recent write.</hint>
        <hint level="3">Strong consistency guarantees that reads always return the most recently committed version of data.</hint>
      </hints>
      <tags>
        <tag>cosmos-db</tag>
        <tag>consistency</tag>
        <tag>distributed-systems</tag>
      </tags>
    </question>

    <question id="dp900-q037">
      <category-ref>cat-non-relational</category-ref>
      <difficulty>basic</difficulty>
      <title>Azure Cache for Redis</title>
      <scenario>A web application experiences slow performance because it frequently queries the same data from the database. The team wants to store frequently accessed data in memory to reduce database load and improve response times.</scenario>
      <question-text>Which Azure service provides an in-memory data store for caching scenarios?</question-text>
      <choices>
        <choice id="A">Azure Cosmos DB</choice>
        <choice id="B">Azure Table Storage</choice>
        <choice id="C">Azure Cache for Redis</choice>
        <choice id="D">Azure Blob Storage</choice>
      </choices>
      <correct-answer>C</correct-answer>
      <hints>
        <hint level="1">Consider which Azure service is specifically designed for in-memory caching.</hint>
        <hint level="2">This service is based on the popular open-source Redis cache.</hint>
        <hint level="3">Azure Cache for Redis provides a fully managed in-memory data store based on Redis.</hint>
      </hints>
      <tags>
        <tag>redis</tag>
        <tag>caching</tag>
        <tag>performance</tag>
      </tags>
    </question>

    
    <question id="dp900-q038">
      <category-ref>cat-analytics</category-ref>
      <difficulty>basic</difficulty>
      <title>Azure Synapse Analytics Overview</title>
      <scenario>A company wants to unify their data warehousing and big data analytics on a single platform. They need to perform SQL queries on structured data and Spark-based analytics on large data sets, all within one integrated service.</scenario>
      <question-text>Which Azure service provides a unified analytics platform for data warehousing and big data?</question-text>
      <choices>
        <choice id="A">Azure Databricks</choice>
        <choice id="B">Azure Synapse Analytics</choice>
        <choice id="C">Azure HDInsight</choice>
        <choice id="D">Azure Data Factory</choice>
      </choices>
      <correct-answer>B</correct-answer>
      <hints>
        <hint level="1">Consider which service combines data warehousing with big data analytics capabilities.</hint>
        <hint level="2">This service integrates SQL pools, Spark pools, and data integration in one platform.</hint>
        <hint level="3">Azure Synapse Analytics is a unified analytics service combining enterprise data warehousing and big data analytics.</hint>
      </hints>
      <tags>
        <tag>synapse</tag>
        <tag>analytics</tag>
        <tag>data-warehouse</tag>
      </tags>
    </question>

    <question id="dp900-q039">
      <category-ref>cat-analytics</category-ref>
      <difficulty>intermediate</difficulty>
      <title>Data Warehouse Concepts</title>
      <scenario>A retail company wants to analyze years of sales data to identify trends across products, stores, and time periods. They need to store historical data from multiple source systems in a way optimized for complex analytical queries and reporting.</scenario>
      <question-text>What type of data store is specifically designed for this analytical reporting scenario?</question-text>
      <choices>
        <choice id="A">OLTP database</choice>
        <choice id="B">Data warehouse</choice>
        <choice id="C">Document database</choice>
        <choice id="D">Key-value store</choice>
      </choices>
      <correct-answer>B</correct-answer>
      <hints>
        <hint level="1">Consider which data store is optimized for analytical queries on historical data.</hint>
        <hint level="2">This type of store consolidates data from multiple sources for reporting and analysis.</hint>
        <hint level="3">A data warehouse is a central repository optimized for analytical queries and reporting on historical data.</hint>
      </hints>
      <tags>
        <tag>data-warehouse</tag>
        <tag>analytics</tag>
        <tag>olap</tag>
      </tags>
    </question>

    <question id="dp900-q040">
      <category-ref>cat-analytics</category-ref>
      <difficulty>intermediate</difficulty>
      <title>Star Schema Design</title>
      <scenario>A data warehouse architect is designing a schema for sales analysis. They create a central Sales table containing measures like quantity and revenue, surrounded by dimension tables for Product, Customer, Time, and Store that contain descriptive attributes.</scenario>
      <question-text>What type of data warehouse schema is being described?</question-text>
      <choices>
        <choice id="A">Normalized schema</choice>
        <choice id="B">Snowflake schema</choice>
        <choice id="C">Star schema</choice>
        <choice id="D">Flat schema</choice>
      </choices>
      <correct-answer>C</correct-answer>
      <hints>
        <hint level="1">Consider the shape formed by a central table with surrounding dimension tables.</hint>
        <hint level="2">This schema has denormalized dimension tables directly connected to a fact table.</hint>
        <hint level="3">A star schema has a central fact table surrounded by denormalized dimension tables, forming a star shape.</hint>
      </hints>
      <tags>
        <tag>star-schema</tag>
        <tag>data-modeling</tag>
        <tag>data-warehouse</tag>
      </tags>
    </question>

    <question id="dp900-q041">
      <category-ref>cat-analytics</category-ref>
      <difficulty>intermediate</difficulty>
      <title>Fact and Dimension Tables</title>
      <scenario>A data warehouse contains a table that stores daily sales transactions with columns for sale amount, quantity sold, and foreign keys to other tables. It contains millions of rows representing measurable business events.</scenario>
      <question-text>What type of data warehouse table stores measurable business events with numeric values?</question-text>
      <choices>
        <choice id="A">Fact table</choice>
        <choice id="B">Dimension table</choice>
        <choice id="C">Lookup table</choice>
        <choice id="D">Bridge table</choice>
      </choices>
      <correct-answer>A</correct-answer>
      <hints>
        <hint level="1">Consider which table type contains the quantitative data for analysis.</hint>
        <hint level="2">This table stores measurements and metrics that can be aggregated.</hint>
        <hint level="3">A fact table contains quantitative data (measures) about business events that can be analyzed.</hint>
      </hints>
      <tags>
        <tag>fact-table</tag>
        <tag>data-modeling</tag>
        <tag>data-warehouse</tag>
      </tags>
    </question>

    <question id="dp900-q042">
      <category-ref>cat-analytics</category-ref>
      <difficulty>basic</difficulty>
      <title>Azure Data Factory Overview</title>
      <scenario>A company needs to orchestrate data movement from multiple sources including on-premises SQL Server, cloud storage, and SaaS applications. They need to schedule data pipelines, transform data, and load it into their data warehouse.</scenario>
      <question-text>Which Azure service provides data integration and orchestration capabilities?</question-text>
      <choices>
        <choice id="A">Azure Synapse Analytics</choice>
        <choice id="B">Azure Databricks</choice>
        <choice id="C">Azure Data Factory</choice>
        <choice id="D">Azure Stream Analytics</choice>
      </choices>
      <correct-answer>C</correct-answer>
      <hints>
        <hint level="1">Consider which service is designed specifically for data movement and orchestration.</hint>
        <hint level="2">This service creates, schedules, and manages data pipelines.</hint>
        <hint level="3">Azure Data Factory is a cloud-based data integration service for creating data-driven workflows.</hint>
      </hints>
      <tags>
        <tag>data-factory</tag>
        <tag>etl</tag>
        <tag>data-integration</tag>
      </tags>
    </question>

    <question id="dp900-q043">
      <category-ref>cat-analytics</category-ref>
      <difficulty>basic</difficulty>
      <title>Azure Databricks Overview</title>
      <scenario>A data science team needs a collaborative environment for building machine learning models and performing big data analytics. They prefer using Apache Spark and want interactive notebooks for data exploration and model development.</scenario>
      <question-text>Which Azure service provides a collaborative Apache Spark-based analytics platform?</question-text>
      <choices>
        <choice id="A">Azure Databricks</choice>
        <choice id="B">Azure Machine Learning</choice>
        <choice id="C">Azure HDInsight</choice>
        <choice id="D">Azure Synapse Analytics</choice>
      </choices>
      <correct-answer>A</correct-answer>
      <hints>
        <hint level="1">Consider which service is optimized for Apache Spark with collaborative notebooks.</hint>
        <hint level="2">This service is based on Databricks and integrates natively with Azure.</hint>
        <hint level="3">Azure Databricks is an Apache Spark-based analytics platform with collaborative notebooks and workspace.</hint>
      </hints>
      <tags>
        <tag>databricks</tag>
        <tag>spark</tag>
        <tag>big-data</tag>
      </tags>
    </question>

    <question id="dp900-q044">
      <category-ref>cat-analytics</category-ref>
      <difficulty>intermediate</difficulty>
      <title>Azure Stream Analytics</title>
      <scenario>A manufacturing company needs to analyze sensor data from IoT devices in real-time. They want to detect anomalies as they occur and trigger alerts within seconds of unusual readings being recorded.</scenario>
      <question-text>Which Azure service is designed for real-time stream processing and analytics?</question-text>
      <choices>
        <choice id="A">Azure Data Factory</choice>
        <choice id="B">Azure Synapse Analytics</choice>
        <choice id="C">Azure Databricks</choice>
        <choice id="D">Azure Stream Analytics</choice>
      </choices>
      <correct-answer>D</correct-answer>
      <hints>
        <hint level="1">Consider which service processes streaming data in real-time.</hint>
        <hint level="2">This service uses SQL-like queries to analyze data streams.</hint>
        <hint level="3">Azure Stream Analytics is a real-time analytics service for processing streaming data from IoT and events.</hint>
      </hints>
      <tags>
        <tag>stream-analytics</tag>
        <tag>real-time</tag>
        <tag>iot</tag>
      </tags>
    </question>

    <question id="dp900-q045">
      <category-ref>cat-analytics</category-ref>
      <difficulty>basic</difficulty>
      <title>Power BI Overview</title>
      <scenario>A business team needs to create interactive reports and dashboards from their company's data. They want to share visualizations with colleagues and enable self-service analytics for business users without requiring deep technical skills.</scenario>
      <question-text>Which Microsoft tool provides self-service business intelligence and data visualization?</question-text>
      <choices>
        <choice id="A">Azure Synapse Analytics</choice>
        <choice id="B">Azure Data Factory</choice>
        <choice id="C">Power BI</choice>
        <choice id="D">Azure Analysis Services</choice>
      </choices>
      <correct-answer>C</correct-answer>
      <hints>
        <hint level="1">Consider which tool is designed for business users to create reports and dashboards.</hint>
        <hint level="2">This tool provides interactive visualizations and self-service BI capabilities.</hint>
        <hint level="3">Power BI is Microsoft's business analytics service for creating interactive reports and dashboards.</hint>
      </hints>
      <tags>
        <tag>power-bi</tag>
        <tag>visualization</tag>
        <tag>business-intelligence</tag>
      </tags>
    </question>

    <question id="dp900-q046">
      <category-ref>cat-analytics</category-ref>
      <difficulty>intermediate</difficulty>
      <title>Data Lake Concepts</title>
      <scenario>An organization wants to store all their data - structured, semi-structured, and unstructured - in a central repository in its raw native format. Data scientists and analysts can then process and analyze this data using various tools as needed.</scenario>
      <question-text>What type of data storage architecture stores data in its raw native format?</question-text>
      <choices>
        <choice id="A">Data lake</choice>
        <choice id="B">Data warehouse</choice>
        <choice id="C">Data mart</choice>
        <choice id="D">Operational database</choice>
      </choices>
      <correct-answer>A</correct-answer>
      <hints>
        <hint level="1">Consider which storage paradigm keeps data in its original format without transformation.</hint>
        <hint level="2">This approach stores all types of data at any scale in native format.</hint>
        <hint level="3">A data lake stores raw data in its native format, allowing flexible processing and analysis later.</hint>
      </hints>
      <tags>
        <tag>data-lake</tag>
        <tag>architecture</tag>
        <tag>big-data</tag>
      </tags>
    </question>

    <question id="dp900-q047">
      <category-ref>cat-analytics</category-ref>
      <difficulty>intermediate</difficulty>
      <title>Azure HDInsight</title>
      <scenario>A company wants to run open-source big data frameworks including Hadoop, Spark, Hive, and Kafka in Azure. They need a managed cluster service that supports these popular open-source analytics technologies.</scenario>
      <question-text>Which Azure service provides managed clusters for popular open-source big data frameworks?</question-text>
      <choices>
        <choice id="A">Azure HDInsight</choice>
        <choice id="B">Azure Databricks</choice>
        <choice id="C">Azure Synapse Analytics</choice>
        <choice id="D">Azure Data Factory</choice>
      </choices>
      <correct-answer>A</correct-answer>
      <hints>
        <hint level="1">Consider which service provides managed Hadoop, Spark, Hive, and Kafka clusters.</hint>
        <hint level="2">This service is Azure's offering for running various open-source analytics frameworks.</hint>
        <hint level="3">Azure HDInsight is a managed cloud service for running open-source analytics frameworks like Hadoop and Spark.</hint>
      </hints>
      <tags>
        <tag>hdinsight</tag>
        <tag>hadoop</tag>
        <tag>open-source</tag>
      </tags>
    </question>

    <question id="dp900-q048">
      <category-ref>cat-analytics</category-ref>
      <difficulty>intermediate</difficulty>
      <title>Modern Data Warehouse Architecture</title>
      <scenario>An enterprise is designing their analytics architecture. They plan to ingest raw data into a data lake, use data pipelines to transform and load data into a data warehouse, and then serve it to Power BI for visualization.</scenario>
      <question-text>What is this integrated approach to analytics architecture commonly called?</question-text>
      <choices>
        <choice id="A">Lambda architecture</choice>
        <choice id="B">Medallion architecture</choice>
        <choice id="C">Kappa architecture</choice>
        <choice id="D">Modern data warehouse</choice>
      </choices>
      <correct-answer>D</correct-answer>
      <hints>
        <hint level="1">Consider the pattern that combines data lake, warehouse, and BI tools.</hint>
        <hint level="2">This architecture integrates multiple Azure data services for end-to-end analytics.</hint>
        <hint level="3">A modern data warehouse architecture combines data lake, data warehouse, and BI services for comprehensive analytics.</hint>
      </hints>
      <tags>
        <tag>architecture</tag>
        <tag>data-warehouse</tag>
        <tag>data-lake</tag>
      </tags>
    </question>

    <question id="dp900-q049">
      <category-ref>cat-analytics</category-ref>
      <difficulty>basic</difficulty>
      <title>Data Visualization Concepts</title>
      <scenario>A sales manager wants to see monthly revenue trends over the past year. They need a visual representation that shows how values change over time with data points connected to show the trend.</scenario>
      <question-text>Which type of data visualization is best suited for showing trends over time?</question-text>
      <choices>
        <choice id="A">Pie chart</choice>
        <choice id="B">Bar chart</choice>
        <choice id="C">Line chart</choice>
        <choice id="D">Scatter plot</choice>
      </choices>
      <correct-answer>C</correct-answer>
      <hints>
        <hint level="1">Consider which visualization connects data points to show progression.</hint>
        <hint level="2">This chart type is ideal for displaying continuous data over time intervals.</hint>
        <hint level="3">Line charts are best for showing trends and changes in values over time.</hint>
      </hints>
      <tags>
        <tag>visualization</tag>
        <tag>charts</tag>
        <tag>analytics</tag>
      </tags>
    </question>

    <question id="dp900-q050">
      <category-ref>cat-analytics</category-ref>
      <difficulty>intermediate</difficulty>
      <title>Azure Purview Data Governance</title>
      <scenario>An enterprise needs to create a unified data catalog across their Azure and on-premises data sources. They want to automatically discover and classify sensitive data, track data lineage, and enable business users to find and understand available data assets.</scenario>
      <question-text>Which Azure service provides unified data governance and catalog capabilities?</question-text>
      <choices>
        <choice id="A">Azure Data Factory</choice>
        <choice id="B">Azure Monitor</choice>
        <choice id="C">Azure Synapse Analytics</choice>
        <choice id="D">Microsoft Purview</choice>
      </choices>
      <correct-answer>D</correct-answer>
      <hints>
        <hint level="1">Consider which service provides data discovery, classification, and lineage tracking.</hint>
        <hint level="2">This service creates a unified map of data assets across an organization.</hint>
        <hint level="3">Microsoft Purview provides unified data governance including data catalog, lineage, and classification.</hint>
      </hints>
      <tags>
        <tag>purview</tag>
        <tag>data-governance</tag>
        <tag>data-catalog</tag>
      </tags>
    </question>
  </questions>

  <glossary>
    <term id="term-structured">
      <name>Structured Data</name>
      <definition>Data organized in a defined format with fixed schema, typically stored in rows and columns in relational databases.</definition>
    </term>
    <term id="term-semi-structured">
      <name>Semi-Structured Data</name>
      <definition>Data with some organizational properties like tags or markers but without a rigid schema, such as JSON or XML.</definition>
    </term>
    <term id="term-unstructured">
      <name>Unstructured Data</name>
      <definition>Data without a predefined format or organization, such as documents, images, videos, and audio files.</definition>
    </term>
    <term id="term-oltp">
      <name>OLTP (Online Transaction Processing)</name>
      <definition>Database systems optimized for managing transaction-oriented applications with many concurrent users performing quick operations.</definition>
    </term>
    <term id="term-olap">
      <name>OLAP (Online Analytical Processing)</name>
      <definition>Database systems optimized for complex analytical queries, aggregations, and historical data analysis.</definition>
    </term>
    <term id="term-etl">
      <name>ETL (Extract, Transform, Load)</name>
      <definition>A data integration process that extracts data from sources, transforms it to meet requirements, and loads it into a destination system.</definition>
    </term>
    <term id="term-data-warehouse">
      <name>Data Warehouse</name>
      <definition>A central repository of integrated data from multiple sources, optimized for analytical queries and reporting.</definition>
    </term>
    <term id="term-data-lake">
      <name>Data Lake</name>
      <definition>A storage repository that holds vast amounts of raw data in its native format until needed for analysis.</definition>
    </term>
    <term id="term-nosql">
      <name>NoSQL</name>
      <definition>Non-relational databases designed for specific data models with flexible schemas, including document, key-value, column-family, and graph databases.</definition>
    </term>
    <term id="term-partition-key">
      <name>Partition Key</name>
      <definition>A value used to distribute data across physical partitions in distributed databases like Cosmos DB for scalability and performance.</definition>
    </term>
    <term id="term-star-schema">
      <name>Star Schema</name>
      <definition>A data warehouse schema with a central fact table surrounded by denormalized dimension tables, forming a star pattern.</definition>
    </term>
    <term id="term-fact-table">
      <name>Fact Table</name>
      <definition>A table in a data warehouse containing quantitative data (measures) about business events that can be aggregated and analyzed.</definition>
    </term>
  </glossary>
</certification-exam>